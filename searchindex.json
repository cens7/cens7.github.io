{"categories":[],"posts":[{"content":"一、背景 在开发过程中，我们经常要对敏感信息做加密。例如: 账号、密码、银行卡号等。在目前项目的开发过程中，我们使用手动显示的方式调用加解密。但是当某个表需要加密的字段变多时，需要手动调用加解密的方式太多，过于繁琐，遂想有没有办法来实现非手动调用的自动加解密。\n二、思路 先决条件: 加解密bean(此bean会被spring托管、需要读配置文件的密钥key)；MybatisTypeHandler；使用mybatis-generator plugin生成Mapper、xml、Entity；自动完成加解密不用手动调用。\n问题: 使用MybatisTypeHadler，并注入加解密；但是用generator生成xml与Entity时，类的属性会变成加密类，我需要类的属性还是String类，那能不能自定义generator plugin替换原生generator类属性加密类替换为String类。\n思路: 使用MybatisTypeHadler实现自动加解密，并将bean注入到MybatisTypeHandler里，并集成到generator plugin里。使用自定义plugin替换类属性类型。\n三、实现 1.新建自定义加密对象\n@Getter @Setter @Builder @NoArgsConstructor @AllArgsConstructor public class MybatisCryptNumber { private String value; }  2.新建自定义加解密TypeHandler\n@Slf4j @AllArgsConstructor @MappedTypes(MybatisCryptNumber.class) public class CryptNumberTypeHandler extends BaseTypeHandler\u0026lt;String\u0026gt; { /** * 加解密bean */ private final CryptNumber cryptNumber; /** * 用于定义在Mybatis设置参数时该如何把Java类型的参数转换为对应的数据库类型 * * @param ps 当前的PreparedStatement对象 * @param i 当前参数的位置 * @param parameter 当前参数的Java对象 * @param jdbcType 当前参数的数据库类型 * * @throws SQLException */ @Override public void setNonNullParameter(PreparedStatement ps, int i, String parameter, JdbcType jdbcType) throws SQLException { // 只要 parameter 非空都进行加密 try { ps.setObject(i, cryptNumber.encrypt(parameter)); } catch (Exception e) { log.error(\u0026quot;setNonNullParameter error\u0026quot;, e); throw new SQLException(e); } } /** * 用于在Mybatis获取数据结果集时如何把数据库类型转换为对应的Java类型 * * @param rs 当前的结果集 * @param columnName 当前的字段名称 * * @return 转换后的Java对象 * * @throws SQLException */ @Override public String getNullableResult(ResultSet rs, String columnName) throws SQLException { String r = rs.getString(columnName); try { return r == null ? null : cryptNumber.decrypt(r); } catch (Exception e) { log.error(\u0026quot;getNullableResult error\u0026quot;, e); throw new SQLException(e); } } /** * 用于在Mybatis通过字段位置获取字段数据时把数据库类型转换为对应的Java类型 * * @param rs 当前的结果集 * @param columnIndex 当前字段的位置 * * @return 转换后的Java对象 * * @throws SQLException */ @Override public String getNullableResult(ResultSet rs, int columnIndex) throws SQLException { try { String r = rs.getString(columnIndex); return r == null ? null : cryptNumber.decrypt(r); } catch (Exception e) { log.error(\u0026quot;getNullableResult error\u0026quot;, e); throw new SQLException(e); } } /** * 用于Mybatis在调用存储过程后把数据库类型的数据转换为对应的Java类型 * * @param cs 当前的CallableStatement执行后的CallableStatement * @param columnIndex 当前输出参数的位置 * * @return * * @throws SQLException */ @Override public String getNullableResult(CallableStatement cs, int columnIndex) throws SQLException { try { // 兼容待修复的数据 String r = cs.getString(columnIndex); return r == null ? null : cryptNumber.decrypt(r); } catch (Exception e) { log.error(\u0026quot;getNullableResult error\u0026quot;, e); throw new SQLException(e); } } }  3.注册自定义TypeHandler\n\t@Bean public CryptNumber cryptNumber(){ return new CryptNumber(); } @Bean public CryptNumberTypeHandler cryptNumberTypeHandler(CryptNumber cryptNumber) { return new CryptNumberTypeHandler(cryptNumber); } @Bean @Primary public SqlSessionFactory customSqlSessionFactory(@Qualifier(\u0026quot;customDataSource\u0026quot;) DataSource dataSource, CryptNumberTypeHandler cryptNumberTypeHandler) throws Exception { SqlSessionFactoryBean bean = new SqlSessionFactoryBean(); bean.setDataSource(dataSource); bean.setTypeHandlers(cryptNumberTypeHandler,); bean.setMapperLocations( new PathMatchingResourcePatternResolver().getResources(\u0026quot;classpath*:mybatis/**/*.xml\u0026quot;)); return bean.getObject(); }  4.新增自定义generator plugin\npublic class CryptReplacePlugin extends PluginAdapter { private List\u0026lt;String\u0026gt; replaceTypes; public CryptReplacePlugin() { super(); replaceTypes = Lists .newArrayList(\u0026quot;MybatisCryptSimple\u0026quot;, \u0026quot;MybatisCryptNumber\u0026quot;, \u0026quot;MybatisCryptBase62\u0026quot;, \u0026quot;MybatisCryptBase36\u0026quot;); } @Override public boolean validate(List\u0026lt;String\u0026gt; warnings) { return true; } /** * 拦截普通字段 */ @Override public boolean modelBaseRecordClassGenerated(TopLevelClass topLevelClass, IntrospectedTable introspectedTable) { for (Field field : topLevelClass.getFields()) { FullyQualifiedJavaType type = field.getType(); // 替换加密字段类型 if (replaceTypes.contains(type.getShortName())) { field.setType(new FullyQualifiedJavaType(\u0026quot;java.lang.String\u0026quot;)); } } return true; } @Override public boolean modelExampleClassGenerated(TopLevelClass topLevelClass, IntrospectedTable introspectedTable) { List\u0026lt;InnerClass\u0026gt; innerClasses = topLevelClass.getInnerClasses(); for (InnerClass innerClass : innerClasses) { List\u0026lt;Method\u0026gt; methods = innerClass.getMethods(); for (Method method : methods) { List\u0026lt;Parameter\u0026gt; parameters = method.getParameters(); List\u0026lt;Parameter\u0026gt; replaceParams = new LinkedList\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; parameters.size(); i++) { Parameter parameter = parameters.get(i); FullyQualifiedJavaType type = parameter.getType(); if(replaceTypes.contains(type.getShortName())){ // 将生成的加密属性参数替换为String类型参数 Parameter nParam = new Parameter(new FullyQualifiedJavaType(\u0026quot;java.lang.String\u0026quot;), parameter.getName()); System.out.println(111); replaceParams.add(nParam); }else{ replaceParams.add(parameter); } } if(CollectionUtil.isNotEmpty(replaceParams)){ ReflectUtil.setFieldValue(method, \u0026quot;parameters\u0026quot;, replaceParams); } } } return true; } /** * 拦截主键字段 */ @Override public boolean modelPrimaryKeyClassGenerated(TopLevelClass topLevelClass, IntrospectedTable introspectedTable) { return true; } }  完成编码，使用一下。1.在原先的generator.xml里添加自定义的generator plugin。\u0026lt;plugin type=\u0026quot;CryptReplacePlugin\u0026quot; /\u0026gt;  2.修改需要加密的字段javaType并指定typeHandler。\u0026lt;table tableName=\u0026quot;Account\u0026quot; domainObjectName=\u0026quot;AccountDO\u0026quot;\u0026gt; \u0026lt;generatedKey column=\u0026quot;id\u0026quot; sqlStatement=\u0026quot;mysql\u0026quot; identity=\u0026quot;true\u0026quot;/\u0026gt; \u0026lt;columnOverride column=\u0026quot;PASSWORD\u0026quot; javaType=\u0026quot;MybatisCryptNumber\u0026quot; typeHandler=\u0026quot;CryptNumberTypeHandler\u0026quot;/\u0026gt; \u0026lt;/table\u0026gt;  执行一下generator plugin，并测试通过。\n以上。\n","id":0,"section":"posts","summary":"一、背景 在开发过程中，我们经常要对敏感信息做加密。例如: 账号、密码、银行卡号等。在目前项目的开发过程中，我们使用手动显示的方式调用加解密。但","tags":["数据库","mybatis"],"title":"Mybatis自动加解密","uri":"https://cens7.github.io/2020/09/mybatis%E8%87%AA%E5%8A%A8%E5%8A%A0%E8%A7%A3%E5%AF%86/","year":"2020"},{"content":"一、背景 当前项目基于springBoot, 且配置中心使用的阿里云acm，但是配置中心暂未整合动态配置。\n二、思路 首先整理了以下几点切入点:\n spring framework有一个@RefreshScope注解，用来做配置刷新。 阿里acm官方有文档帮助整合。 看看acm控制台都有哪些功能。 了解spring-actuator。  根据以上几个切入点开始整合。\n三、接入过程 1. 问题 按照文档 的描述，只需要添加maven依赖，然后直接使用@RefreshScope就可以了。但是实际这样存在问题。\n问题1: 在acm控制后台，只能查到推送轨迹，而没有监听查询记录。 问题2: 在acm控制后台修改后，client端配置并没有更新。\n❓推测1: 我的应用部署在容器里，之后暴露端口到机器上，机器上有一层nginx代理，再上面还有一层LBS。会不会是acm server推过来压根就失败了，只是推送轨迹显示推送成功。\n❓推测2:会不会是我的监听器注册失败，所以在acm server上没有监听查询记录。\n2. 解决过程 1⃣️首先看一下spring-cloud-starter-acm里都有什么。\n2⃣️里面直接就是starter相关的类。找到AcmAutoConfiguration类，看看里面都有什么。\n3⃣️看一下这几个类的源码，果然在AcmContextRefresher类里看到了registerDiamondListener()方法，这个就是注册监听器的核心逻辑了。\n4⃣️debug AcmContextRefresher类，看到当registerDiamondListenersForApplications里的acmPropertySourceRepository.getAll() size为0时，不会去调用registerDiamondListener() 5⃣️点进去debug一下，可以看到这里的逻辑是找到一个AcmPropertySource类型的源参数类后放到list，之后根据这个list来迭代，注册listener。现在的问题是找不到AcmPropertySource类型的类。6⃣️acm阿里官网文档有说：\n 访问 ip+端口/actuator/acm 访问acm的Endpoint。\n { \u0026quot;runtime\u0026quot;: { \u0026quot;sources\u0026quot;: [ { \u0026quot;lastSynced\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;dataId\u0026quot;: \u0026quot;\u0026quot; } ], \u0026quot;refreshHistory\u0026quot;: [ ] }, \u0026quot;config\u0026quot;: { \u0026quot;group\u0026quot;: \u0026quot;group\u0026quot;, \u0026quot;timeOut\u0026quot;: 3000, \u0026quot;endpoint\u0026quot;: \u0026quot;acm.aliyun.com\u0026quot;, \u0026quot;namespace\u0026quot;: \u0026quot;xxxxx\u0026quot;, \u0026quot;accessKey\u0026quot;: \u0026quot;xxx\u0026quot;, \u0026quot;secretKey\u0026quot;: \u0026quot;xxxx\u0026quot;, \u0026quot;ramRoleName\u0026quot;: null, \u0026quot;fileExtension\u0026quot;: \u0026quot;yaml\u0026quot; } }  我的访问结果dataId、lastSynced、refreshHistory都没有值，而acm阿里官网是有值的。\n阿里官网的acm长这样：\n{ \u0026quot;runtime\u0026quot;: { \u0026quot;sources\u0026quot;: [ { \u0026quot;dataId\u0026quot;: \u0026quot;com.alibaba.cloud.acm:sample-app.properties\u0026quot;, \u0026quot;lastSynced\u0026quot;: \u0026quot;2017-10-10 10:46:27\u0026quot; } ], \u0026quot;refreshHistory\u0026quot;: [ { \u0026quot;timestamp\u0026quot;: \u0026quot;2017-10-10 10:46:24\u0026quot;, \u0026quot;dataId\u0026quot;: \u0026quot;com.alibaba.cloud.acm:sample-app.properties\u0026quot;, \u0026quot;md5\u0026quot;: \u0026quot;8692ae986ec7bc345b3f0f4de602ff13\u0026quot; } ] }, \u0026quot;config\u0026quot;: { \u0026quot;group\u0026quot;: \u0026quot;DEFAULT_GROUP\u0026quot;, \u0026quot;timeOut\u0026quot;: 3000, \u0026quot;endpoint\u0026quot;: \u0026quot;xxx\u0026quot;, \u0026quot;namespace\u0026quot;: \u0026quot;xxx\u0026quot;, \u0026quot;accessKey\u0026quot;: \u0026quot;xxx\u0026quot;, \u0026quot;secretKey\u0026quot;: \u0026quot;xxx\u0026quot; } }  仔细观察官网的结构，发现dataId跟我在acm控制台设置的dataId长的比较类似。脑瓜子一闪，这里的dataId是不是就是acm控制台配置的dataId。7⃣️再次debug刚刚的acmPropertySourceRepository.getAll()，仔细看结果发现了dataId。此时的PropertySource并不是CompositePropertySource，而是BootstrapPropertySource,所以这个result为空. 8⃣️明白以上之后，我直接重写掉这部分逻辑是不是就可以了。\n3.重写方案 1⃣️重写AcmPropertySourceRepository\npublic class AcmCustomPropertySourceRepository extends AcmPropertySourceRepository { private final ApplicationContext applicationContext; public AcmCustomPropertySourceRepository(ApplicationContext applicationContext) { super(applicationContext); this.applicationContext = applicationContext; } public List\u0026lt;AcmPropertySource\u0026gt; getAll() { List\u0026lt;AcmPropertySource\u0026gt; result = new ArrayList\u0026lt;\u0026gt;(); ConfigurableApplicationContext ctx = (ConfigurableApplicationContext)applicationContext; for (PropertySource p : ctx.getEnvironment().getPropertySources()) { if (p instanceof AcmPropertySource) { result.add((AcmPropertySource)p); } else if (p instanceof BootstrapPropertySource) { BootstrapPropertySource bps = (BootstrapPropertySource)p; PropertySource propertySource = bps.getDelegate(); if (propertySource instanceof AcmPropertySource) { result.add((AcmPropertySource)propertySource); } } } return result; } }  2⃣️配置类\n@Configuration public class AcmCustomConfiguration implements ApplicationContextAware { private ApplicationContext applicationContext; @Bean(\u0026quot;acmCustomPropertySourceRepository\u0026quot;) @Primary public AcmPropertySourceRepository acmPropertySourceRepository() { return new AcmCustomPropertySourceRepository(applicationContext); } @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException { this.applicationContext = applicationContext; } }  debug看一下，这时候的result有值，并且listner成功注册。 校验： 1.再次访问: ip+端口/actuator/acm\n{ \u0026quot;runtime\u0026quot;: { \u0026quot;sources\u0026quot;: [ { \u0026quot;lastSynced\u0026quot;: \u0026quot;2020-08-05 17:35:02\u0026quot;, \u0026quot;dataId\u0026quot;: \u0026quot;com.xxxxtest2.yaml\u0026quot; } ], \u0026quot;refreshHistory\u0026quot;: [ { \u0026quot;timestamp\u0026quot;: \u0026quot;2020-08-05 17:39:38\u0026quot;, \u0026quot;dataId\u0026quot;: \u0026quot;com.xxxxxtest2.yaml\u0026quot;, \u0026quot;md5\u0026quot;: \u0026quot;20f6572e9f097d8cbf075f83eabe958e\u0026quot; } ] }, \u0026quot;config\u0026quot;: { \u0026quot;group\u0026quot;: \u0026quot;group\u0026quot;, \u0026quot;timeOut\u0026quot;: 3000, \u0026quot;endpoint\u0026quot;: \u0026quot;acm.aliyun.com\u0026quot;, \u0026quot;namespace\u0026quot;: \u0026quot;xxxx\u0026quot;, \u0026quot;accessKey\u0026quot;: \u0026quot;xxxx\u0026quot;, \u0026quot;secretKey\u0026quot;: \u0026quot;xxxx\u0026quot;, \u0026quot;ramRoleName\u0026quot;: null, \u0026quot;fileExtension\u0026quot;: \u0026quot;yaml\u0026quot; } }  2.在acm控制台修改配置, 已经看到了正确的监听记录。 四、使用 1. 使用@Value() 当使用@Value读取配置文件，且需要配置文件热更新时，需要在类上添加@RefreshScope注解。\n例如：\n@RequestMapping(\u0026quot;/test\u0026quot;) @RestController @RefreshScope public class TestController { @Value(\u0026quot;${shareLink.joinUrl}\u0026quot;) private String str; @GetMapping(\u0026quot;/test\u0026quot;) public String test(){ return str; } }  2.使用@Bean 当使用@Bean读取一个配置的properties class，且需要配置的properties class热更新时，需要在@Bean的注解下面添加@RefreshScope注解。\n例如：\n@Getter @Setter @ConfigurationProperties(prefix = \u0026quot;aliyun.oss\u0026quot;) public class OssProperties { private String endpoint; private String regionId; private String region; private String accessKeyId; private String accessKeySecret; private String stsRoleArn; private String bucket; private String userId; }  @Configuration @EnableConfigurationProperties(OssProperties.class) public class OssAutoConfiguration { @Bean @RefreshScope public OSSClient ossClient(OssProperties ossProperties) { CredentialsProvider credentialsProvider = new DefaultCredentialProvider(ossProperties.getAccessKeyId(), ossProperties.getAccessKeySecret()); ClientConfiguration config = new ClientConfiguration(); return new OSSClient(ossProperties.getEndpoint(), credentialsProvider, config); } }  以上，搞定。\n","id":1,"section":"posts","summary":"一、背景 当前项目基于springBoot, 且配置中心使用的阿里云acm，但是配置中心暂未整合动态配置。 二、思路 首先整理了以下几点切入点: spring f","tags":["springBoot","acm","配置中心"],"title":"Springboot整合acm动态配置","uri":"https://cens7.github.io/2020/08/springboot%E6%95%B4%E5%90%88acm%E5%8A%A8%E6%80%81%E9%85%8D%E7%BD%AE/","year":"2020"},{"content":"背景 在前面，我们已经接入了mockito，但是上个版本的单元测试需要接入的测试中间件太多了，本次做了一次缩减，删掉其他测试中间件，只保留最原始的mockito与springframework Test。\n使用 1. 添加依赖 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.mockito\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mockito-core\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-test\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt;  2. 具体使用  @MockBean修饰需要测试的类 声明调用特定方法时，传入指定参数，返回指定指  when(xxx.yyy(zzz)).thenReturn(aaa); // 当调用xxx.yyy()方法且入参是zzz时，返回aaa；如果入参不是zzz，则返回null。 when(xxx.yyy()).thenAnswer(t -\u0026gt; {});// 当调用xxx.yyy()方法时，没有返回值，执行一个自定义的函数体。   test原本需要测试的方法  例：\nservice调用链：\n@Service @AllArgsConstructor public class MockService { private final UserReferenceService userReferenceService; public long testMockMethod(Long userId) { if (userId \u0026lt; 0) { return -1; } return userReferenceService.getUserByUserId(userId).getUserId(); } }  单元测试使用：\n@ActiveProfiles(\u0026quot;dev\u0026quot;) @SpringBootTest class MockServiceTest { // 需要测试的类 @Autowired private MockService mockService; // 需要mock的类 @MockBean private UserReferenceService userReferenceService; @Test void testMockMethod() { // 当传入-1, 返回100 Mockito.when(userReferenceService.getUserByUserId(-1L)) .thenReturn(UserBaseInfoVO.builder().userId(100L).build()); // 当传入-2, 返回200 Mockito.when(userReferenceService.getUserByUserId(-2L)) .thenReturn(UserBaseInfoVO.builder().userId(200L).build()); long o1 = mockService.testMockMethod(-1L); Assert.assertEquals(\u0026quot;比较错误\u0026quot;, 100L, o1); long o2 = mockService.testMockMethod(-2L); Assert.assertEquals(\u0026quot;比较错误\u0026quot;, 200L, o2); } }  使用起来比之前集成的更加简单。\n以上。\n","id":2,"section":"posts","summary":"背景 在前面，我们已经接入了mockito，但是上个版本的单元测试需要接入的测试中间件太多了，本次做了一次缩减，删掉其他测试中间件，只保留最原","tags":["Java","测试"],"title":"单元测试Mockito使用心得2","uri":"https://cens7.github.io/2020/07/%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95mockito%E4%BD%BF%E7%94%A8%E5%BF%83%E5%BE%972/","year":"2020"},{"content":"背景 前面我配置了同应用多数据源的。但是在实际开发中，我们需要使用事务，保障业务与数据的可用性。那当配置了多数据源时，默认的事务管理器实际时失效了，它找不到具体需要管理的DataSource。\n思考 看源码，@Transactional注解默认使用了一个PlatformTransactionManager继续将PlatformTransactionManager点进去: 这是spring事务管理的核心接口，使用aop拦截它的实现。它有两个默认的实现org.springframework.transaction.jta.JtaTransactionManager 和org.springframework.jdbc.datasource.DataSourceTransactionManager 。\n 从之前的配置知道，我并没有使用jta，所以继续往下走，看DataSourceTransactionManager 的实现。\n implementation for a single JDBC {@link javax.sql.DataSource}. This class is capable of working in any environment with any JDBC driver, as long as the setup uses a {@code javax.sql.DataSource} as its {@code Connection} factory mechanism.Binds a JDBC Connection from the specified DataSource to the current thread, potentially allowing for one thread-bound Connection per DataSource.\n 从DataSourceTransactionManager 源码的第一段落就可以发现，它只需要绑定一个DataSource就行了。\n由此，我只需要按照springboot的关键词搜索，那么我就能找到一个事务的默认配置。然后被我找到了DataSourceTransactionManagerAutoConfiguration 到这里就很简单了，按照springboot的机制，exclude掉这个类，然后配置一个类似的。我有两个不同的DataSouce， 只需要将这两个DataSource配置给每个不同的事务管理器，然后再使用事务的时候声明使用哪个事务管理器就可以。\nChainedTransactionManager 可以用来管理多个事务管理器。\n使用 @Configuration public class DataSourceTransactionConfig { @Bean(name=\u0026quot;tm1\u0026quot;) DataSourceTransactionManager tm1(@Qualifier (\u0026quot;ds1\u0026quot;) DataSource datasource) { return new DataSourceTransactionManager(datasource); } @Bean(name=\u0026quot;tm2\u0026quot;) DataSourceTransactionManager tm2(@Qualifier (\u0026quot;ds2\u0026quot;) DataSource datasource) { return new DataSourceTransactionManager(datasource); } @Transactional @Bean(name = \u0026quot;chainedTransactionManager\u0026quot;) public ChainedTransactionManager transactionManager(@Qualifier(\u0026quot;tm1\u0026quot;) PlatformTransactionManager tm1, @Qualifier(\u0026quot;tm2\u0026quot;) PlatformTransactionManager tm2) { return new ChainedTransactionManager(tm1, tm2); } }  测试一下，通过。\n","id":3,"section":"posts","summary":"背景 前面我配置了同应用多数据源的。但是在实际开发中，我们需要使用事务，保障业务与数据的可用性。那当配置了多数据源时，默认的事务管理器实际时失","tags":["SpringBoot","数据库"],"title":"SpringBoot配置多数据源二","uri":"https://cens7.github.io/2020/06/springboot%E9%85%8D%E7%BD%AE%E5%A4%9A%E6%95%B0%E6%8D%AE%E6%BA%902/","year":"2020"},{"content":"前言 在使用CompletableFuture之前，我一直在使用Future处理多线程的一些业务场景。在查jdk一些api时发现了了CompletableFuture。\n其中，它的前言部分就吸引到了我：\n A Future that may be explicitly completed (setting its value and status), and may be used as a CompletionStage, supporting dependent functions and actions that trigger upon its completion. When two or more threads attempt to complete, completeExceptionally, or cancel a CompletableFuture, only one of them succeeds.\nCompletable是可以明确的完成(设置其值和状态)并可以用作CompletionStage的Future，支持函数调用，以及触发线程完成后的操作。\n 首先对比 Future，CompletableFuture 优点在于：\n 不需要手工分配线程，JDK 自动分配 代码语义清晰，异步任务链式调用 支持编排异步任务  CompletableFuture api图关系:1.创建CompletableFuture public static \u0026lt;U\u0026gt; CompletableFuture\u0026lt;U\u0026gt; completedFuture(U value) public static CompletableFuture\u0026lt;Void\u0026gt; runAsync(Runnable runnable) public static \u0026lt;U\u0026gt; CompletableFuture\u0026lt;U\u0026gt; supplyAsync(Supplier\u0026lt;U\u0026gt; supplier) public static CompletableFuture\u0026lt;Void\u0026gt; runAsync(Runnable runnable, Executor executor) public static \u0026lt;U\u0026gt; CompletableFuture\u0026lt;U\u0026gt; supplyAsync(Supplier\u0026lt;U\u0026gt; supplier, Executor executor)  第一个方法创建一个具有默认结果的 CompletableFuture，这个没啥好讲。我们重点讲述下下面四个异步方法。\n前两个方法 runAsync 不支持返回值，而 supplyAsync可以支持返回结果。\n这个两个方法默认将会使用公共的 ForkJoinPool 线程池执行，这个线程池默认线程数是 CPU 的核数。\n 可以设置 JVM option:-Djava.util.concurrent.ForkJoinPool.common.parallelism 来设置 ForkJoinPool 线程池的线程数\n 使用共享线程池将会有个弊端，一旦有任务被阻塞，将会造成其他任务没机会执行。所以强烈建议使用后两个方法，根据任务类型不同，主动创建线程池，进行资源隔离，避免互相干扰。\n2.设置任务结果 CompletableFuture 提供以下方法，可以主动设置任务结果。\n boolean complete(T value) boolean completeExceptionally(Throwable ex)  第一个方法，主动设置 CompletableFuture 任务执行结果，若返回 true，表示设置成功。如果返回 false，设置失败，这是因为任务已经执行结束，已经有了执行结果。\n示例代码如下：\n// 执行异步任务 CompletableFuture cf = CompletableFuture.supplyAsync(() -\u0026gt; { System.out.println(\u0026quot;cf 任务执行开始\u0026quot;); sleep(10, TimeUnit.SECONDS); System.out.println(\u0026quot;cf 任务执行结束\u0026quot;); return \u0026quot;楼下小姐姐\u0026quot;; }); // Executors.newSingleThreadScheduledExecutor().execute(() -\u0026gt; { sleep(5, TimeUnit.SECONDS); System.out.println(\u0026quot;主动设置 cf 任务结果\u0026quot;); // 设置任务结果，由于 cf 任务未执行结束，结果返回 true cf.complete(\u0026quot;mavic\u0026quot;); }); // 由于 cf 未执行结束，将会被阻塞。5 秒后，另外一个线程主动设置任务结果 System.out.println(\u0026quot;get:\u0026quot; + cf.get()); // 等待 cf 任务执行结束 sleep(10, TimeUnit.SECONDS); // 由于已经设置任务结果，cf 执行结束任务结果将会被抛弃 System.out.println(\u0026quot;get:\u0026quot; + cf.get()); /*** * cf 任务执行开始 * 主动设置 cf 任务结果 * get:mavic * cf 任务执行结束 * get:mavic */  这里需要注意一点，一旦 complete 设置成功，CompletableFuture 返回结果就不会被更改，即使后续 CompletableFuture 任务执行结束。\n第二个方法，给 CompletableFuture 设置异常对象。若设置成功，如果调用 get 等方法获取结果，将会抛错。\n示例代码如下：\n// 执行异步任务 CompletableFuture cf = CompletableFuture.supplyAsync(() -\u0026gt; { System.out.println(\u0026quot;cf 任务执行开始\u0026quot;); sleep(10, TimeUnit.SECONDS); System.out.println(\u0026quot;cf 任务执行结束\u0026quot;); return \u0026quot;楼下小姐姐\u0026quot;; }); // Executors.newSingleThreadScheduledExecutor().execute(() -\u0026gt; { sleep(5, TimeUnit.SECONDS); System.out.println(\u0026quot;主动设置 cf 异常\u0026quot;); // 设置任务结果，由于 cf 任务未执行结束，结果返回 true cf.completeExceptionally(new RuntimeException(\u0026quot;啊，挂了\u0026quot;)); }); // 由于 cf 未执行结束，前 5 秒将会被阻塞。后续程序抛出异常，结束 System.out.println(\u0026quot;get:\u0026quot; + cf.get()); /*** * cf 任务执行开始 * 主动设置 cf 异常 * java.util.concurrent.ExecutionException: java.lang.RuntimeException: 啊，挂了 * ...... */  3.CompletionStage CompletableFuture 分别实现两个接口 Future与 CompletionStage。Future 接口都比较熟悉，这里主要讲讲 CompletionStage。\nCompletableFuture 大部分方法来自CompletionStage 接口，正是因为这个接口，CompletableFuture才有如此强大功能。\n想要理解 CompletionStage 接口，我们需要先了解任务的时序关系的。我们可以将任务时序关系分为以下几种：\n 串行执行关系 并行执行关系 AND 汇聚关系 OR 汇聚关系  4.串行执行关系 任务串行执行，下一个任务必须等待上一个任务完成才可以继续执行。CompletionStage 有四组接口可以描述串行这种关系，分别为:\npublic \u0026lt;U\u0026gt; CompletableFuture\u0026lt;U\u0026gt; thenApply(Function\u0026lt;? super T,? extends U\u0026gt; fn) public CompletableFuture\u0026lt;Void\u0026gt; thenAccept(Consumer\u0026lt;? super T\u0026gt; action) public CompletableFuture\u0026lt;Void\u0026gt; thenRun(Runnable action) public \u0026lt;U\u0026gt; CompletableFuture\u0026lt;U\u0026gt; thenCompose(Function\u0026lt;? super T, ? extends CompletionStage\u0026lt;U\u0026gt;\u0026gt; fn) public \u0026lt;U\u0026gt; CompletableFuture\u0026lt;U\u0026gt; thenApplyAsync(Function\u0026lt;? super T,? extends U\u0026gt; fn) public CompletableFuture\u0026lt;Void\u0026gt; thenAcceptAsync(Consumer\u0026lt;? super T\u0026gt; action) public CompletableFuture\u0026lt;Void\u0026gt; thenRunAsync(Runnable action) public \u0026lt;U\u0026gt; CompletableFuture\u0026lt;U\u0026gt; thenComposeAsync(Function\u0026lt;? super T, ? extends CompletionStage\u0026lt;U\u0026gt;\u0026gt; fn)  thenApply 方法需要传入核心参数为 Function\u0026lt;T,R\u0026gt;类型。这个类核心方法为：\n R apply(T t)\n 所以这个接口将会把上一个任务返回结果当做入参，执行结束将会返回结果。\nthenAccept 方法需要传入参数对象为 Consumer类型，这个类核心方法为：\n void accept(T t)\n 返回值 void 可以看出，这个方法不支持返回结果，但是需要将上一个任务执行结果当做参数传入。\nthenRun 方法需要传入参数对象为 Runnable 类型，这个类比较熟悉，核心方法既不支持传入参数，也不会返回执行结果。\nthenCompose 方法作用与 thenApply 一样，只不过 thenCompose 需要返回新的 CompletionStage。这么理解比较抽象，可以集合代码一起理解。\nCompletableFuture\u0026lt;String\u0026gt; cf = CompletableFuture.supplyAsync(() -\u0026gt; \u0026quot;hello, 楼下小姐姐\u0026quot;); cf.thenApply(String::toLowerCase); cf.thenCompose(s -\u0026gt; CompletableFuture.supplyAsync(s::toLowerCase));  方法中带有 Async ，代表可以异步执行，这个系列还有重载方法，可以传入自定义的线程池，上图未展示，读者只可以自行查看 API。\n最后我们通过代码展示 thenApply 使用方式：\nCompletableFuture\u0026lt;String\u0026gt; cf = CompletableFuture.supplyAsync(() -\u0026gt; \u0026quot;hello,楼下小姐姐\u0026quot;)// 1 .thenApply(s -\u0026gt; s + \u0026quot;@mavic\u0026quot;) // 2 .thenApply(String::toUpperCase); // 3 System.out.println(cf.join()); // 输出结果 HELLO,楼下小姐姐@mavic  这段代码比较简单，首先我们开启一个异步任务，接着串行执行后续两个任务。任务 2 需要等待任务1 执行完成，任务 3 需要等待任务 2。\n 上面方法，需要记住 Function\u0026lt;T，R\u0026gt;，Consumer，Runnable 三者区别，根据场景选择使用。\n 5.AND 汇聚关系 AND 汇聚关系代表所有任务完成之后，才能进行下一个任务。 如上所示，只有任务 A 与任务 B 都完成之后，任务 C 才会开始执行。\nCompletionStage 有以下接口描述这种关系。\npublic \u0026lt;U,V\u0026gt; CompletableFuture\u0026lt;V\u0026gt; thenCombine(CompletionStage\u0026lt;? extends U\u0026gt; other, BiFunction\u0026lt;? super T,? super U,? extends V\u0026gt; fn) public \u0026lt;U\u0026gt; CompletableFuture\u0026lt;Void\u0026gt; thenAcceptBoth(CompletionStage\u0026lt;? extends U\u0026gt; other, BiConsumer\u0026lt;? super T, ? super U\u0026gt; action) public CompletableFuture\u0026lt;Void\u0026gt; runAfterBoth(CompletionStage\u0026lt;?\u0026gt; other, Runnable action) public \u0026lt;U,V\u0026gt; CompletableFuture\u0026lt;V\u0026gt; thenCombineAsync(CompletionStage\u0026lt;? extends U\u0026gt; other, BiFunction\u0026lt;? super T,? super U,? extends V\u0026gt; fn) public \u0026lt;U\u0026gt; CompletableFuture\u0026lt;Void\u0026gt; thenAcceptBothAsync(CompletionStage\u0026lt;? extends U\u0026gt; other, BiConsumer\u0026lt;? super T, ? super U\u0026gt; action) public CompletableFuture\u0026lt;Void\u0026gt; runAfterBothAsync(CompletionStage\u0026lt;?\u0026gt; other, Runnable action)  thenCombine 方法核心参数 BiFunction ，作用与 Function一样，只不过 BiFunction 可以接受两个参数，而 Function 只能接受一个参数。\nthenAcceptBoth 方法核心参数BiConsumer 作用也与 Consumer一样，不过其需要接受两个参数。\nrunAfterBoth 方法核心参数最简单，上面已经介绍过，不再介绍。\n这三组方法只能完成两个任务 AND 汇聚关系，如果需要完成多个任务汇聚关系，需要使用 CompletableFuture#allOf，不过这里需要注意，这个方法是不支持返回任务结果。\n6.OR 汇聚关系 有 AND 汇聚关系，当然也存在 OR 汇聚关系。OR 汇聚关系代表只要多个任务中任一任务完成，就可以接着接着执行下一任务。\nCompletionStage 有以下接口描述这种关系：\npublic \u0026lt;U\u0026gt; CompletableFuture\u0026lt;U\u0026gt; applyToEither(CompletionStage\u0026lt;? extends T\u0026gt; other, Function\u0026lt;? super T, U\u0026gt; fn) public CompletableFuture\u0026lt;Void\u0026gt; acceptEither(CompletionStage\u0026lt;? extends T\u0026gt; other, Consumer\u0026lt;? super T\u0026gt; action) public CompletableFuture\u0026lt;Void\u0026gt; runAfterEither(CompletionStage\u0026lt;?\u0026gt; other, Runnable action) public \u0026lt;U\u0026gt; CompletableFuture\u0026lt;U\u0026gt; applyToEitherAsync(CompletionStage\u0026lt;? extends T\u0026gt; other, Function\u0026lt;? super T, U\u0026gt; fn) public CompletableFuture\u0026lt;Void\u0026gt; acceptEitherAsync(CompletionStage\u0026lt;? extends T\u0026gt; other, Consumer\u0026lt;? super T\u0026gt; action) public CompletableFuture\u0026lt;Void\u0026gt; runAfterEitherAsync(CompletionStage\u0026lt;?\u0026gt; other, Runnable action) public static CompletableFuture\u0026lt;Object\u0026gt; anyOf(CompletableFuture\u0026lt;?\u0026gt;... cfs)  前面三组接口方法传参与 AND 汇聚关系一致，这里也不再详细解释了。\n当然 OR 汇聚关系可以使用 CompletableFuture#anyOf 执行多个任务。\n下面示例代码展示如何使用 applyToEither 完成 OR 关系。\nCompletableFuture\u0026lt;String\u0026gt; cf = CompletableFuture.supplyAsync(() -\u0026gt; { sleep(5, TimeUnit.SECONDS); return \u0026quot;hello,楼下小姐姐\u0026quot;; });// 1 CompletableFuture\u0026lt;String\u0026gt; cf2 = cf.supplyAsync(() -\u0026gt; { sleep(3, TimeUnit.SECONDS); return \u0026quot;hello，mavic\u0026quot;; }); // 执行 OR 关系 CompletableFuture\u0026lt;String\u0026gt; cf3 = cf2.applyToEither(cf, s -\u0026gt; s); // 输出结果，由于 cf2 只休眠 3 秒，优先执行完毕 System.out.println(cf2.join()); // 结果：hello，mavic  7.异常处理 CompletableFuture 方法执行过程若产生异常，当调用 get，join获取任务结果才会抛出异常。\nCompletionStage 提供几个方法，可以优雅处理异常。\npublic CompletableFuture\u0026lt;T\u0026gt; exceptionally(Function\u0026lt;Throwable, ? extends T\u0026gt; fn) public CompletableFuture\u0026lt;T\u0026gt; whenComplete(BiConsumer\u0026lt;? super T, ? super Throwable\u0026gt; action) public \u0026lt;U\u0026gt; CompletableFuture\u0026lt;U\u0026gt; handle(BiFunction\u0026lt;? super T, Throwable, ? extends U\u0026gt; fn) public CompletableFuture\u0026lt;T\u0026gt; whenCompleteAsync(BiConsumer\u0026lt;? super T, ? super Throwable\u0026gt; action) public \u0026lt;U\u0026gt; CompletableFuture\u0026lt;U\u0026gt; handleAsync(BiFunction\u0026lt;? super T, Throwable, ? extends U\u0026gt; fn)  exceptionally 使用方式类似于 try..catch 中 catch代码块中异常处理。\nwhenComplete 与 handle 方法就类似于 try..catch..finanlly 中 finally 代码块。无论是否发生异常，都将会执行的。这两个方法区别在于 handle 支持返回结果。\n下面示例代码展示 handle 用法：\nCompletableFuture\u0026lt;Integer\u0026gt; f0 = CompletableFuture.supplyAsync(() -\u0026gt; (7 / 0)) .thenApply(r -\u0026gt; r * 10) .handle((integer, throwable) -\u0026gt; { // 如果异常存在,打印异常，并且返回默认值 if (throwable != null) { throwable.printStackTrace(); return 0; } else { // 如果 return integer; } }); System.out.println(f0.join()); /** * java.util.concurrent.CompletionException: java.lang.ArithmeticException: / by zero * ..... * * 0 */  总结 JDK8 提供 CompletableFuture 功能非常强大，可以编排异步任务，完成串行执行，并行执行，AND 汇聚关系，OR 汇聚关系。\n不过这个类方法实在太多，且方法还需要传入各种函数式接口，新手刚开始使用会直接会被弄懵逼。这里再总结一下三类核心参数的作用：\n Function 这类函数接口既支持接收参数，也支持返回值 Consumer 这类接口函数只支持接受参数，不支持返回值 Runnable 这类接口不支持接受参数，也不支持返回值  搞清楚函数参数作用以后，然后根据串行，AND 汇聚关系，OR 汇聚关系归纳一下相关方法，这样就比较好理解了\n","id":4,"section":"posts","summary":"前言 在使用CompletableFuture之前，我一直在使用Future处理多线程的一些业务场景。在查jdk一些api时发现了了Compl","tags":["Java","多线程"],"title":"CompletableFuture二三事","uri":"https://cens7.github.io/2020/05/completablefuture%E4%BA%8C%E4%B8%89%E4%BA%8B/","year":"2020"},{"content":"背景 随着业务的发展，在开发过程中，需要在一个工程里连接多个数据库，并兼容springBoot原本的与mybatis整合。\n思路 看源码，过程大体是: 创建DataSource — 根据DataSource创建SqlSessionFactory — 根据SqlSessionFactory创建SqlSessionTemplate\n这里，我将多个数据库作为多个数据源创建出来，并根据@MapperScan扫描多个包的机制，将不同的SqlSessionTemplate创建出来。\n过程 创建第一个数据源:\n@Configuration @MapperScan(basePackages = \u0026quot;com.business.db1.mapper\u0026quot;, sqlSessionFactoryRef = \u0026quot;db1SqlSessionFactory\u0026quot;) public class Db1DataSourceConfig { @Bean(name = \u0026quot;db1DataSource\u0026quot;) @Primary @ConfigurationProperties(prefix = \u0026quot;spring.datasource.db1\u0026quot;) public DataSource getDateSource() { DataSource dataSource = DataSourceBuilder.create().build(); return dataSource; } @Bean(name = \u0026quot;db1SqlSessionFactory\u0026quot;) @Primary public SqlSessionFactory memberSqlSessionFactory(@Qualifier(\u0026quot;db1DataSource\u0026quot;) DataSource datasource)throws Exception { SqlSessionFactoryBean bean = new SqlSessionFactoryBean(); bean.setDataSource(datasource); bean.setMapperLocations(new PathMatchingResourcePatternResolver().getResources(\u0026quot;classpath*:com.business.db1/*.xml\u0026quot;)); org.apache.ibatis.session.Configuration configuration = new org.apache.ibatis.session.Configuration(); configuration.setMapUnderscoreToCamelCase(true); bean.setConfiguration(configuration); return bean.getObject(); } @Bean(\u0026quot;db1SqlSessionTemplate\u0026quot;) @Primary public SqlSessionTemplate memberSqlSessionTemplate(@Qualifier(\u0026quot;db1SqlSessionFactory\u0026quot;) SqlSessionFactory sessionFactory) { return new SqlSessionTemplate(sessionFactory); } }  创建第二个数据源:\n@Configuration @MapperScan(basePackages = \u0026quot;com.business.db2.mapper\u0026quot;, sqlSessionFactoryRef = \u0026quot;db2SqlSessionFactory\u0026quot;) public class Db2DataSourceConfig { @Bean(name = \u0026quot;db2DataSource\u0026quot;) @ConfigurationProperties(prefix = \u0026quot;spring.datasource.db2\u0026quot;) public DataSource getDateSource() { return DataSourceBuilder.create().build(); } @Bean(name = \u0026quot;db2SqlSessionFactory\u0026quot;) public SqlSessionFactory primarySqlSessionFactory(@Qualifier(\u0026quot;db2DataSource\u0026quot;) DataSource datasource) throws Exception { SqlSessionFactoryBean bean = new SqlSessionFactoryBean(); bean.setDataSource(datasource); bean.setMapperLocations(new PathMatchingResourcePatternResolver().getResources(\u0026quot;classpath*:com.business.db2/*.xml\u0026quot;)); org.apache.ibatis.session.Configuration configuration = new org.apache.ibatis.session.Configuration(); configuration.setMapUnderscoreToCamelCase(true); bean.setConfiguration(configuration); return bean.getObject(); } @Bean(\u0026quot;db2SqlSessionTemplate\u0026quot;) public SqlSessionTemplate primarySqlSessionTemplate( @Qualifier(\u0026quot;db2SqlSessionFactory\u0026quot;) SqlSessionFactory sessionFactory) { return new SqlSessionTemplate(sessionFactory); } }  配置之后就可以。\n新问题 我的db1数据源是用sharding做的分库分表，需要同时在一个工程里访问一个分库分表的数据源，一个普通的数据源。\n使用后了解sharding配置后最终也是创建一个DataSource出来，交给spring托管；那我是不是将上面的db1里的数据源换成sharding的配置就可以了呢？ 说干就干。\n@Configuration @MapperScan(basePackages = \u0026quot;com.business.db1.mapper\u0026quot;, sqlSessionFactoryRef = \u0026quot;db1SqlSessionFactory\u0026quot;) public class Db1DataSourceConfig { @Bean(name = \u0026quot;db1DataSource\u0026quot;) @Primary public DataSource getShardingDataSource(ShardingSliceProperties shardingSliceProperties) throws SQLException { ShardingRuleConfiguration shardingRuleConfig = new ShardingRuleConfiguration(); TableRuleConfiguration tableRuleConfiguration = new TableRuleConfiguration(shardingSliceProperties.getSliceTable(), shardingSliceProperties.getSliceDatabase() + \u0026quot;_${0..15}.\u0026quot; + shardingSliceProperties.getSliceTable() + \u0026quot;_${0..127}\u0026quot;); // 设置表规则 shardingRuleConfig.getTableRuleConfigs().add(tableRuleConfiguration); // 设置分库规则 shardingRuleConfig.setDefaultDatabaseShardingStrategyConfig(new StandardShardingStrategyConfiguration( shardingSliceProperties.getSliceDatabaseKey(), new OrderDatabaseAlgorithm())); // 设置分表规则 shardingRuleConfig.setDefaultTableShardingStrategyConfig(new StandardShardingStrategyConfiguration( shardingSliceProperties.getSliceTableKey(), new OrderTableAlgorithm())); // 配置分库数据源 Map\u0026lt;String, DataSource\u0026gt; dataSourceMap = new HashMap\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; 16; i++) { HikariConfig hikariConfig = new HikariConfig(); hikariConfig.setMinimumIdle(5); hikariConfig.setMaximumPoolSize(25); hikariConfig.setUsername(shardingSliceProperties.getUsername()); hikariConfig.setPassword(shardingSliceProperties.getPassword()); hikariConfig.setDriverClassName(shardingSliceProperties.getDriverClassName()); hikariConfig.setJdbcUrl(shardingSliceProperties.getJdbcUrl()+ \u0026quot;_\u0026quot; + i); HikariDataSource hikariDataSource = new HikariDataSource(hikariConfig); dataSourceMap.put(shardingSliceProperties.getSliceDatabase() + \u0026quot;_\u0026quot; + i, hikariDataSource); } Properties props = new Properties(); // 设置显示sql props.put(ShardingPropertiesConstant.SQL_SHOW.getKey(), String.valueOf(Boolean.TRUE)); // 配置默认数据源 HikariConfig hikariConfig = new HikariConfig(); hikariConfig.setDriverClassName(shardingSliceProperties.getDriverClassName()); hikariConfig.setJdbcUrl(shardingSliceProperties.getJdbcUrl()); hikariConfig.setUsername(shardingSliceProperties.getUsername()); hikariConfig.setPassword(shardingSliceProperties.getPassword()); hikariConfig.setMaximumPoolSize(25); hikariConfig.setMinimumIdle(5); HikariDataSource hikariDataSource = new HikariDataSource(hikariConfig); dataSourceMap.put(shardingSliceProperties.getSliceDatabase(), hikariDataSource); shardingRuleConfig.setDefaultDataSourceName(shardingSliceProperties.getSliceDatabase()); DataSource dataSource = ShardingDataSourceFactory.createDataSource(dataSourceMap, shardingRuleConfig, props); return dataSource; } @Bean(name = \u0026quot;db1SqlSessionFactory\u0026quot;) @Primary public SqlSessionFactory memberSqlSessionFactory(@Qualifier(\u0026quot;db1DataSource\u0026quot;) DataSource datasource)throws Exception { SqlSessionFactoryBean bean = new SqlSessionFactoryBean(); bean.setDataSource(datasource); bean.setMapperLocations(new PathMatchingResourcePatternResolver().getResources(\u0026quot;classpath*:com.business.db1/*.xml\u0026quot;)); org.apache.ibatis.session.Configuration configuration = new org.apache.ibatis.session.Configuration(); configuration.setMapUnderscoreToCamelCase(true); bean.setConfiguration(configuration); return bean.getObject(); } @Bean(\u0026quot;db1SqlSessionTemplate\u0026quot;) @Primary public SqlSessionTemplate memberSqlSessionTemplate(@Qualifier(\u0026quot;db1SqlSessionFactory\u0026quot;) SqlSessionFactory sessionFactory) { return new SqlSessionTemplate(sessionFactory); } }  启动报错，DataSouce NullPointException。 debug运行了一下，发现执行了org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration这个自动配置，在启动类exclude这个自动配置类搞定。\n启动测试没问题。搞定。\n","id":5,"section":"posts","summary":"背景 随着业务的发展，在开发过程中，需要在一个工程里连接多个数据库，并兼容springBoot原本的与mybatis整合。 思路 看源码，过程大体","tags":["springBoot","数据库","分库分表"],"title":"SpringBoot配置多数据源一","uri":"https://cens7.github.io/2020/05/springboot%E9%85%8D%E7%BD%AE%E5%A4%9A%E6%95%B0%E6%8D%AE%E6%BA%901/","year":"2020"},{"content":"Netty-Socketio使用 1.添加依赖 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.corundumstudio.socketio\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;netty-socketio\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.7.18\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;  2.配置 2.1 配置 redisson 略，前面有redisson的博文，我介绍过。\n2.2 配置socketio的Configuration public Configuration getConfig(){ Configuration config = new Configuration(); config.setHostname(\u0026quot;localhost\u0026quot;); config.setPort(9092); InputStream ssl = WebSocketServer.class.getResourceAsStream(jksPath);//证书地址 config.setPort.setKeyStore(ssl); final SocketIOServer server = new SocketIOServer(config); }  2.3 注册监听器 注册连接监听器与断开监听器\nvoid addListener() { socketServer.addConnectListener(new ConnectListener() { @Override public void onConnect(SocketIOClient socketIOClient) { connectThreadPool.submit(new Runnable() { @Override public void run() { HandshakeData handshakeData = socketIOClient.getHandshakeData(); // 消息接收方 String system = handshakeData.getSingleUrlParam(HandshakeParamsDTO.FROM); socketIOClient.joinRoom(system); // 将用户信息存到缓存 } }); } }); socketServer.addDisconnectListener(new DisconnectListener() { @Override public void onDisconnect(SocketIOClient socketIOClient) { disconnectThreadPool.submit(new Runnable() { @Override public void run() { //从缓存删除用户信息 } }); } }); }  2.4 启动/断开服务  启动socketServer.start(); 断开socketServer.stop();  2.5 发消息 单个发送：\npublic void sendMessageToUser(WebSocketDataDTO message) { Packet packet = new Packet(PacketType.MESSAGE); packet.setData(message.getMessage()); String sessionId = redisHelper.getSessionIdOfUser(message); // 从缓存取出用户信息 if(!StringUtils.isBlank(sessionId)) { socketServer.getClient(UUID.fromString(sessionId)).send(packet, new AckCallback\u0026lt;AckResult\u0026gt;(AckResult.class) { @Override public void onSuccess(AckResult result) { } }); } }  广播发送：\npublic void sendRoomMessage(WebSocketDataDTO message) { if(StringUtils.isBlank(message.getTo())) { Packet packet = new Packet(PacketType.MESSAGE); packet.setData(message.getMessage()); socketServer.getRoomOperations(message.getTo()).send(packet); } }  ","id":6,"section":"posts","summary":"Netty-Socketio使用 1.添加依赖 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.corundumstudio.socketio\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;netty-socketio\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.7.18\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 2.配置 2.1 配置 redisson 略，前面有redisson的博文，我介绍过。 2.2 配置socketio的C","tags":["webSocket","Java"],"title":"Netty Socketio使用","uri":"https://cens7.github.io/2020/03/netty-socketio%E4%BD%BF%E7%94%A8/","year":"2020"},{"content":"背景 团队推行单元测试，需要对主要逻辑serice层做单元测试，但是有些service会有外部接口调用或上游接口调用，而因为环境问题，这部分接口又无法掉通，为了解决这个问题，我接入了Mockito。\n使用 1. 添加依赖 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.mockito\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mockito-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.23.4\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt;  2. 具体使用  @InjectMocks修饰需要测试的类 @Mock修饰需要mock掉的类 初始化mock注解 声明调用特定方法时，传入指定参数，返回指定指  when(xxx.yyy(zzz)).thenReturn(aaa); // 当调用xxx.yyy()方法且入参是zzz时，返回aaa；如果入参不是zzz，则返回null。 when(xxx.yyy()).thenAnswer(t -\u0026gt; {});// 当调用xxx.yyy()方法时，没有返回值，执行一个自定义的函数体。   如果被mock的类在需要测试的类中是一个私有的字段，则需要反射修改私有字段的值，将其替换成mock代理类 ReflectionTestUtils.setField(testObject, \u0026ldquo;field\u0026rdquo;, mockObject); test原本需要测试的方法  例：\nservice调用链：\n@Service public class MerchantDataService { @Reference private IMerchantUserService merchantUserService; public Object save(Object obj) { xxxxxx; ResponseEntity = merchantUserService.insert(xxxx); xxxxxx; return xxx; } }  单元测试使用：\n@SpringBootTest(classes = ApplicationStartup.class) @ActiveProfiles(\u0026quot;test\u0026quot;) public class MerchantDataServiceTest extends AbstractTransactionalTestNGSpringContextTests { @InjectMocks @Autowired private IMerchantDataService merchantDataService; @Mock private IMerchantUserService merchantUserService; @BeforeMethod(alwaysRun = true) public void initMock() { // 初始化mock注解 MockitoAnnotations.initMocks(this); ResponseEntity resp = new ResponseEntity().setStatus(Status.SUCCESS); // 当执行merchantUserService.insert方法时，返回申明的对象 when(merchantUserService.insert(new xxxx())).thenReturn(resp); } @Test public void testSave() { Object obj = new Object(); Object resultObj = merchantDataService.save(obj); Assert.assertTrue(respOthers.success()); } }  以上\n","id":7,"section":"posts","summary":"背景 团队推行单元测试，需要对主要逻辑serice层做单元测试，但是有些service会有外部接口调用或上游接口调用，而因为环境问题，这部分接","tags":["Java","测试"],"title":"单元测试Mockito使用心得","uri":"https://cens7.github.io/2020/02/%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95mockito%E4%BD%BF%E7%94%A8%E5%BF%83%E5%BE%97/","year":"2020"},{"content":"背景  听说kotlin跟Java生态无缝集成，尝试一下用kotlin写springBoot应用。\n 启动springboot:\n@SpringBootApplication @EnableScheduling open class NotifyApplication fun main(args: Array\u0026lt;String\u0026gt;) { val app = SpringApplication.run(NotifyApplication::class.java, *args) }  遇到的坑 1. spring无法托管kotlin bean 原因：spring托管bean使用的是aop代理，在默认情况下，使用jdk动态代理与字节码代理组合的模式；而kotlin的class默认是final class\n解决：在kotlin类上加open关键字，在kotlin fun前加open关键字。或者添加kotlin maven依赖，将其标注为allopen。 maven依赖：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.jetbrains.kotlin\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;kotlin-maven-allopen\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${kotlin.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;  2.lombok @Slf4j 注解在kotlin类上失效 原因：lombok.extern.slf4j.Slf4j 注解在kotlin的class上无法使用\n解决：在class中声明 private val logger = LoggerFactory.getLogger(javaClass) 替换原有的@Slf4j方式\n3. spring @Value(${xxx}) 失效 原因：在kotlin中，${}会被编译器特殊解析\n解决：加上转义标识 @Value(\u0026quot;${some.property}\u0026quot;)\n总结：目前只发现了以上几个问题，其他跟java一样使用springboot；另外就是kotlin自己的语法糖了。 ","id":8,"section":"posts","summary":"背景 听说kotlin跟Java生态无缝集成，尝试一下用kotlin写springBoot应用。 启动springboot: @SpringBootApplication @EnableScheduling open class NotifyApplication fun main(args: Array\u0026lt;String\u0026gt;) { val","tags":["Java","Kotlin"],"title":"使用Kotlin写SpringBoot的坑","uri":"https://cens7.github.io/2020/01/%E4%BD%BF%E7%94%A8kotlin%E5%86%99springboot%E7%9A%84%E5%9D%91/","year":"2020"},{"content":"背景\n 项目里使用一些自定义的配置，在bootstrap.yaml里，这些配置会带着黄色的背景色；所以我在想，有没有一种合理的方式可以弄掉背景色。然后发现了springboot-starter。\n 根据官方文档的说明：\n You can easily generate your own configuration metadata file from items annotated with @ConfigurationProperties by using the spring-boot-configuration-processor jar. The jar includes a Java annotation processor which is invoked as your project is compiled. To use the processor, include a dependency on spring-boot-configuration-processor.\n您可以使用spring-boot-configuration-processor jar从带有@ConfigurationProperties注释的项目中轻松生成自己的配置元数据文件。 该jar包含一个Java注释处理器，在您的项目被编译时会被调用。 要使用处理器，请包括对spring-boot-configuration-processor的依赖。\n 明白以上机制后接下来just do it！\n1.添加依赖\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-configuration-processor\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-autoconfigure\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt;  2.添加配置元数据类\n@ConfigurationProperties(prefix = \u0026quot;my\u0026quot;) public class MyProperties { private String property; private StandardCopyOption copyOption; public String getProperty() { return property; } public void setProperty(String property) { this.property = property; } public StandardCopyOption getCopyOption() { return copyOption; } public void setCopyOption(StandardCopyOption copyOption) { this.copyOption = copyOption; } }  3.添加配置类\n@Configuration @EnableConfigurationProperties({MyProperties.class}) public class ApplicationConfiguration { public MyProperties getMyProperties(MyProperties myProperties) { return myProperties; } public void setMyProperties(MyProperties myProperties) { this.myProperties = myProperties; } }  在 META-INF 目录下创建 spring.factories，springboot 自动化配置最终就是要扫描 META-INF/spring.factories 来加载项目的自动化配置类。\nspring.factories配置文件内容:\n org.springframework.boot.autoconfigure.EnableAutoConfiguration= ApplicationConfiguration\n 运行 mvn:install 打包，一个springboot-starter就弄好了。\n测试并通过。以上。\n","id":9,"section":"posts","summary":"背景 项目里使用一些自定义的配置，在bootstrap.yaml里，这些配置会带着黄色的背景色；所以我在想，有没有一种合理的方式可以弄掉背景色","tags":["Java","springboot"],"title":"自定义springboot starter","uri":"https://cens7.github.io/2019/12/%E8%87%AA%E5%AE%9A%E4%B9%89springboot-starter/","year":"2019"},{"content":"常用命令    命令 描述     docker login 登陆   docker logout 登出   docker search [xxx] 搜索镜像   docker pull [xxx] 拉取指定名字的镜像   docker rm [container_id] 根据容器id删除   docker rmi [image_id] 根据镜像id删除   docker ps 查看所有正在运行的容器   docker container ps 查看所有正在运行的容器   docker container ps -a 查看所有容器   docker images 查看所有镜像   docker image ls 查看所有镜像   docker image ls -f dangling=true 查看虚悬镜像(官方发了新版)   dcker system df 查看doker镜像磁盘占用率   docker container rm [container_id] 根据容器id删除容器   docker image rm [image_id] 根据镜像id删除镜像   docker stop [container_id / container_name] 停止指定id的容器   docker start [container_id / container_name] 运行指定id的容器   docker volume create xxx 创建一个数据卷   docker volume ls 查看所有的数据卷   docker volume inspect xxx 查看指定的数据卷   docker volume rm xxx 删除指定的数据卷   docker volume prune 清理无效的数据卷   docker run xxx 运行指定镜像   docker exec -it xxx /bin/bash 进入指定容器   docker network ls 查看容器所有的网络   docker network prune 清理无效的网络   docker network 查看docker网络   docker logs [container_id] 查看指定容器id的日志   docker logs -f 查看指定容器的日志条数   docker port [container_id / container_name] 查询指定容器的端口映射    ","id":10,"section":"posts","summary":"常用命令 命令 描述 docker login 登陆 docker logout 登出 docker search [xxx] 搜索镜像 docker pull [xxx] 拉取指定名字的镜像 docker rm [container_id] 根据容器id删除 docker rmi [image_id] 根据镜像id删除 docker ps 查看所有正在运行的容器","tags":["docker"],"title":"docker使用","uri":"https://cens7.github.io/2019/12/docker%E4%BD%BF%E7%94%A8/","year":"2019"},{"content":"问题 同样的dubbo应用，同事启动只要10秒不到，我启动要2分钟，遂不服。万能的stackoverflow告诉我，我需要设置hosts。\n配置对应的hosts :(1) 127.0.0.1 localhost huanghuandeMacBook-Pro.local ::1 localhost huanghuandeMacBook-Pro.local  配置完成host发现启动从2分钟优化到了6秒！但是会有错误日志！作为强迫症的我岂能忍？！错误日志内容：开始调试：\n1. 先`telent 127.0.0.1 20880`本地dubbo, ok是好的； 2. ll 看一下本地的dubbo provider接口列表； 3. 选中一个，invoke xxx.xx.xx.xxxProvider.test()，ok也是好的。  以上说明我的dubbo接口成功。\n 1. 进入本地nacos看一下dubbo是否注册上去，ok是好的。  捋一捋，dubbo接口是好的，dubbo注册成功，但是为什么启动会报错。\n把改过的hosts改回去：(2)\n 127.0.0.1 localhost ::1 localhost  改回hosts,启动虽然慢了点，但是不报错。\n使用debug大法：\n 将hosts改成 (1) 从上面错误日志那行源码点进去打断点，发现dubbo绑定的地址是127.0.0.1。 将hosts改成 (2) 再启动，dubbo绑定的地址改成了我的内网ip192.168.5.143。很明显因为我配置了主机名，造成dubbo绑定的ip从内网ip192.168.5.143变成了主机ip127.0.0.1；所以这是为什么呢。其实官方已经在这里给了解释。  按照官方给的解释:\n Dubbo选取本地地址的逻辑大致分成了两步； 先去 /etc/hosts 文件中找 hostname 对应的 IP 地址，找到则返回；找不到则转到去 轮询网卡，寻找合适的 IP 地址，找到则返回；找不到返回 null，如果返回 null，则注册 127.0.0.1 这个本地回环地址\n 所以我的问题就是没有找到合适的ip地址而去注册了127.0.0.1这个本地地址。\n于是将我的hosts改成：192.168.5.143 localhost huanghuandeMacBook-Pro.local ::1 localhost huanghuandeMacBook-Pro.local  或者：在启动应用的时候加上启动参数： -DDUBBO_IP_TO_BIND=192.168.5.143  问题解决。\n","id":11,"section":"posts","summary":"问题 同样的dubbo应用，同事启动只要10秒不到，我启动要2分钟，遂不服。万能的stackoverflow告诉我，我需要设置hosts。 配置","tags":["Java","Dubbo","架构","问题"],"title":"Dubbo启动太慢","uri":"https://cens7.github.io/2019/12/dubbo%E5%90%AF%E5%8A%A8%E5%A4%AA%E6%85%A2/","year":"2019"},{"content":"一、背景 介绍：XSS(Cross Site Scripting)指的是用户注入恶意的代码，浏览器和服务器没有对用户的输入进行过滤，导致用户注入的脚本嵌入到了页面中。由于浏览器无法识别这些恶意代码正常解析执行，攻击者的恶意操作被成功执行。\n预防XSS攻击不仅是前端开发人员要做的事情，也是是后端开发人员要做的事情。本篇章节是针对后端开发人员怎么预防XSS攻击。\n常见的XSS攻击分为三种：\n 反射型： 通过在请求地址上加上恶心的HTML代码。 dom型： 通过一些api向网站注入一些恶心的HTML代码。 持久型： 攻击者通过把代码提交到后台数据库中;当用户下次打开的时候就会从后台接收这些恶意的代码。  防范：\n 反射型： 前端通过转义来进行防范以及过滤 dom型：前端通过转义来进行防范以及过滤 持久型：服务端通过转义存储进行防范  对于反射型与dom型的XSS攻击，需要前端做转义。本篇博客主要讲解后端的转义处理。\n二、目的  针对输入包含dom敏感的数据进行过滤 针对输入包含sql相关的敏感信息进行过滤  三、实现方式 使用Filter过滤器使用Filter，将所有的敏感信息替换成空字符串  public class XSSPreventionFilter implements Filter { @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException { XSSRequestWrapper wrapper = new XSSRequestWrapper((HttpServletRequest) request); chain.doFilter(wrapper, response); } class XSSRequestWrapper extends HttpServletRequestWrapper { private Map\u0026lt;String, String[]\u0026gt; sanitizedQueryString; XSSRequestWrapper(HttpServletRequest request) { super(request); } @Override public String getParameter(String name) { String parameter = null; String[] vals = getParameterMap().get(name); if (vals != null \u0026amp;\u0026amp; vals.length \u0026gt; 0) { parameter = vals[0]; } return parameter; } @Override public String[] getParameterValues(String name) { return getParameterMap().get(name); } @Override public Enumeration\u0026lt;String\u0026gt; getParameterNames() { return Collections.enumeration(getParameterMap().keySet()); } @Override public Map\u0026lt;String, String[]\u0026gt; getParameterMap() { if (sanitizedQueryString == null) { Map\u0026lt;String, String[]\u0026gt; res = new HashMap\u0026lt;\u0026gt;(); Map\u0026lt;String, String[]\u0026gt; originalQueryString = super.getParameterMap(); if (originalQueryString != null) { for (String key : originalQueryString.keySet()) { String[] rawVals = originalQueryString.get(key); String[] snzVals = new String[rawVals.length]; for (int i = 0; i \u0026lt; rawVals.length; i++) { snzVals[i] = stripXSS(rawVals[i]); } res.put(stripXSS(key), snzVals); } } sanitizedQueryString = res; } return sanitizedQueryString; } /** * 从字符串中删除所有潜在的恶意字符 * * @param value the raw string * @return the sanitized string */ private String stripXSS(String value) { String cleanValue = null; if (value != null) { cleanValue = Normalizer.normalize(value, Normalizer.Form.NFD); // 删除空字符 cleanValue = cleanValue.replaceAll(\u0026quot;\\0\u0026quot;, \u0026quot;\u0026quot;); // 删除\u0026lt;script\u0026gt;\u0026lt;/script\u0026gt;标签 Pattern scriptPattern = Pattern.compile(\u0026quot;\u0026lt;script\u0026gt;(.*?)\u0026lt;/script\u0026gt;\u0026quot;, Pattern.CASE_INSENSITIVE); cleanValue = scriptPattern.matcher(cleanValue).replaceAll(\u0026quot;\u0026quot;); // 删除src='...' scriptPattern = Pattern.compile(\u0026quot;src[\\r\\n]*=[\\r\\n]*'(.*?)'\u0026quot;, Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL); cleanValue = scriptPattern.matcher(cleanValue).replaceAll(\u0026quot;\u0026quot;); // 删除\u0026lt;/script\u0026gt;标签 scriptPattern = Pattern.compile(\u0026quot;\u0026lt;/script\u0026gt;\u0026quot;, Pattern.CASE_INSENSITIVE); cleanValue = scriptPattern.matcher(cleanValue).replaceAll(\u0026quot;\u0026quot;); // 删除\u0026lt;script ...\u0026gt;标签 scriptPattern = Pattern.compile(\u0026quot;\u0026lt;script(.*?)\u0026gt;\u0026quot;, Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL); cleanValue = scriptPattern.matcher(cleanValue).replaceAll(\u0026quot;\u0026quot;); // 删除eval(...)表达式 scriptPattern = Pattern.compile(\u0026quot;eval\\\\((.*?)\\\\)\u0026quot;, Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL); cleanValue = scriptPattern.matcher(cleanValue).replaceAll(\u0026quot;\u0026quot;); // 删除expression(...)表达式 scriptPattern = Pattern.compile(\u0026quot;expression\\\\((.*?)\\\\)\u0026quot;, Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL); cleanValue = scriptPattern.matcher(cleanValue).replaceAll(\u0026quot;\u0026quot;); // 删除javascript:...表达式 scriptPattern = Pattern.compile(\u0026quot;javascript:\u0026quot;, Pattern.CASE_INSENSITIVE); cleanValue = scriptPattern.matcher(cleanValue).replaceAll(\u0026quot;\u0026quot;); // 删除vbscript:...表达式 scriptPattern = Pattern.compile(\u0026quot;vbscript:\u0026quot;, Pattern.CASE_INSENSITIVE); cleanValue = scriptPattern.matcher(cleanValue).replaceAll(\u0026quot;\u0026quot;); // 删除onload= 表达式 scriptPattern = Pattern.compile(\u0026quot;onload(.*?)=\u0026quot;, Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL); cleanValue = scriptPattern.matcher(cleanValue).replaceAll(\u0026quot;\u0026quot;); // 删除 sql ' 和 ; 字符串 scriptPattern = Pattern.compile(\u0026quot;[';]\u0026quot;, Pattern.CASE_INSENSITIVE); cleanValue = scriptPattern.matcher(cleanValue).replaceAll(\u0026quot;\u0026quot;); // 删除 sql -- 字符 scriptPattern = Pattern.compile(\u0026quot;--\u0026quot;, Pattern.CASE_INSENSITIVE); cleanValue = scriptPattern.matcher(cleanValue).replaceAll(\u0026quot;\u0026quot;); } return cleanValue; } } }  配置Filter过滤器\n配置xss防注入filter bean  @Configuration public class FilterConfig { @Bean public FilterRegistrationBean filterRegistrationBean() { FilterRegistrationBean frb = new FilterRegistrationBean(); frb.setFilter(new XSSPreventionFilter()); frb.setOrder(1); frb.addUrlPatterns(\u0026quot;/*\u0026quot;); return frb; } }  以上完成，搞定。\n","id":12,"section":"posts","summary":"一、背景 介绍：XSS(Cross Site Scripting)指的是用户注入恶意的代码，浏览器和服务器没有对用户的输入进行过滤，导致用户注入的脚本嵌","tags":["Java","安全","xss"],"title":"防xss攻击","uri":"https://cens7.github.io/2019/11/%E9%98%B2xss%E6%94%BB%E5%87%BB/","year":"2019"},{"content":"使用redisson 1.pom依赖  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.redisson\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;redisson\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;   2.配置对应redisson @Configuration public class RedissonConfig { @Autowired(required = false) RedissonProperties redissonProperties; @Bean(destroyMethod = \u0026quot;shutdown\u0026quot;) @ConditionalOnMissingBean(RedissonClient.class) public RedissonClient redissonClient() { if (Objects.nonNull(redissonProperties)) { Config config = new Config(); String[] nodes = redissonProperties.getSentinelNodes().split(\u0026quot;,\u0026quot;); SentinelServersConfig sentinelServersConfig = config.useSentinelServers() .setMasterName(redissonProperties.getMasterName()) .setDatabase(redissonProperties.getDatabase()) .setConnectTimeout(redissonProperties.getConnectTimeout()) .setPassword(redissonProperties.getPassword()); for (String node : nodes) { sentinelServersConfig = sentinelServersConfig.addSentinelAddress(\u0026quot;redis://\u0026quot; + node); } return Redisson.create(config); } else { return null; } } }  3.使用 这里是官方文档\n1) 使用普通锁(可重入锁) 注意：可重入锁lock()几次，就要对应的unlock()几次\npublic static void main(String[] args) { RedissonClient redisson = new RedissonClient; RLock lock = redisson.getLock(\u0026quot;lock\u0026quot;); lock.lock(2, TimeUnit.SECONDS); Thread t = new Thread(() -\u0026gt; { RLock lock1 = redisson.getLock(\u0026quot;lock\u0026quot;); lock1.lock(); lock1.unlock(); }); t.start(); t.join(); lock.unlock(); }  2) 使用公平锁 公平锁秉持先到先得原则，先请求获取锁的线程先获取到锁，后来的线程等待。\n@Autowired private RedissonClient redisson; public void demo() { RLock lock = redisson.getLock(\u0026quot;lock\u0026quot;); lock.lock(2, TimeUnit.SECONDS); Thread t = new Thread(() -\u0026gt; { RLock lock1 = redisson.getLock(\u0026quot;lock\u0026quot;); lock1.lock(); lock1.unlock(); }); t.start(); t.join(); lock.unlock(); }  3) 使用读写锁 @Autowired private RedissonClient redisson; public void demo() throws InterruptedException { final RReadWriteLock lock = redisson.getReadWriteLock(\u0026quot;lock\u0026quot;); lock.writeLock().tryLock(); Thread t = new Thread() { public void run() { RLock r = lock.readLock(); r.lock(2, TimeUnit.SECONDS); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } r.unlock(); }; }; t.start(); t.join(); lock.writeLock().unlock(); t.join(); }  4) 使用红锁 使用redlock需要多个redissonClient，多个redissonClient需要多个互相独立的哨兵，我们的项目里目前只有一个哨兵，所以暂不推荐使用红锁\n上面是4种比较常用的分布式锁机制，我们针对不同业务作出不同选型。\n redisson将各种锁的概念与java的各种锁完美的结合在一起，封装做的非常巧妙，甚至对于CountDownLatch、Semaphore、Atomic等等也有很多精妙绝伦的封装，感兴趣的同学可以研究一下官方文档。\n 注意：1. 不管使用哪一种锁，都需要设置锁的过期时间。 2. 使用lock()、tryLock()时，一定要放在try{}catch(){}中，且unlock一定要放在finally{}里 3. 所有需要使用分布式锁场景的锁名，都要使用枚举、常量统一管理  redisson锁原理 1) tryLock()表示尝试加锁，加锁成功返回true，加锁失败返回false。使用tryLock()加锁，线程没有获取到锁不会阻塞。 使用tryLock()加锁流程： 2) lock() 加锁，此锁已被持有则等待，没有被持有则获取这把锁。使用lock()加锁，线程没有获取到锁会一直阻塞直到获取到锁。 使用lock()加锁流程： 3) 使用可重入锁、公平锁、读写锁时，执行的lua脚本各不相同。    类型 加锁lua 解锁lua     可重入锁 红锁     公平锁     读锁     写锁      4）tryLock()与lock()的使用场景  场景一： 库存抢占。有效库存只有100，多个应用来抢占这100个库存总数。这时使用：lock() 场景二： 退款申请。网络卡顿或其他原因同时段提交多次退款申请，实际只生成一条退款单。这时使用：tryLock()  5）tryLock()与lcok()使用的注意事项  tryLock() 尝试获取锁,不等待，返回获取结果。 tryLock(long waitTime, TimeUnit timeUnit) 尝试获取锁，并等待waitTime个时间单位，之后返回获取结果。 tryLock(long waitTime, long leaseTime, TimeUnit timeUnit) 尝试获取锁，并等待waitTIme个时间单位，并将此锁持有leaseTime个时间单位，之后返回获取结果。 lock() 获取锁，线程阻塞，直到获取到锁为止，锁不过期，直到解锁或者被内部机制释放。 lock(long leaseTime, TimeUnit timeUnit) 获取锁，直到获取到锁为止，持有锁leaseTime个时间单位，之后自动释放锁，也可以提前手动释放。  6）公平锁、可重入锁、读写锁、红锁的使用场景   场景一： 门票只有100张。先到先得。这时使用公平锁  场景二： 1. 门票只有100张，需要抢票。2. 需要把下一张门票修改成vip票。 (可重入锁是在一个线程中多次获取同一把锁。一个线程在执行一个带锁的方法时，该方法中又调用了另一个需要相同锁的方法，则该线程可以直接执行调用的方法，而无需重新获得锁)  场景三： 所有人都能看到库存信息，但同时只有一个人来修改库存。所有的人都能看到库存信息，使用读锁。同时只有一个人来修改库存，使用写锁。多个读锁不互斥，读锁与写锁互斥  场景四： 当需要超级高可用锁的场景时，使用红锁。\n综上所述，使用tryLock还是lock，使用公平锁还是读写锁都是看具体的业务和场景而言。\n  ","id":13,"section":"posts","summary":"使用redisson 1.pom依赖 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.redisson\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;redisson\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 2.配置对应redisson @Configuration public class RedissonConfig { @Autowired(required = false) RedissonProperties redissonProperties; @Bean(destroyMethod = \u0026quot;shutdown\u0026quot;) @ConditionalOnMissingBean(RedissonClient.class) public RedissonClient redissonClient() { if (Objects.nonNull(redissonProperties)) { Config config = new Config(); String[] nodes = redissonProperties.getSentinelNodes().split(\u0026quot;,\u0026quot;); SentinelServersConfig sentinelServersConfig = config.useSentinelServers()","tags":["Java","redis"],"title":"使用redisson做分布式锁","uri":"https://cens7.github.io/2019/11/%E4%BD%BF%E7%94%A8redisson%E5%81%9A%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/","year":"2019"},{"content":" 从数据库工具（比如：navicat）中导出表结构sql。 将sql导入到powerDesigner里。  File → Reverse Engineer → Database选中导出的表结构sql点确定，生成pdm   将comment的值写到name上Tools → Execute Commonds → Edit/Run Script    写入代码点run，然后close弹窗：  Option Explicit ValidationMode = True InteractiveMode = im_Batch Dim mdl 'the current model 'get the current active model Set mdl = ActiveModel If (mdl Is Nothing) Then MsgBox \u0026quot;There is no current Model\u0026quot; ElseIf Not mdl.IsKindOf(PdPDM.cls_Model) Then MsgBox \u0026quot;The current model is not an Physical Data model.\u0026quot; Else ProcessFolder mdl End If 'This routine copy name into code for each table, each column and each view 'of the current folder Private sub ProcessFolder(folder) Dim Tab 'running table for each Tab in folder.tables if not tab.isShortcut then if len(tab.comment) \u0026lt;\u0026gt; 0 then tab.name = tab.comment end if On Error Resume Next Dim col 'running column for each col in tab.columns if len(col.comment) \u0026lt;\u0026gt;0 then col.name =col.comment end if On Error Resume Next next end if next end sub   把code驼峰转为下划线  Option Explicit ValidationMode = True InteractiveMode = im_Batch Dim mdl 'the current model Set mdl = ActiveModel If (mdl Is Nothing) Then MsgBox \u0026quot;There is no current Model\u0026quot; ElseIf Not mdl.IsKindOf(PdPDM.cls_Model) Then MsgBox \u0026quot;The current model is not an Physical Data model.\u0026quot; Else ProcessFolder mdl End If Private sub ProcessFolder(folder) Dim Tab for each Tab in folder.tables Dim col for each col in tab.columns Dim ch Dim exaStr exaStr = \u0026quot;\u0026quot; Dim intCounter Dim intLen Dim arrChars intLen = Len(col.code)-1 redim arrChars(intLen) For intCounter = 0 to intLen arrChars(intCounter) = Mid(col.code, intCounter + 1,1) Next for each ch in arrChars Dim tmpCh tmpCh = LCase(ch) If StrComp(ch, tmpCh)=0 Then exaStr = exaStr + ch Else exaStr = exaStr + \u0026quot;_\u0026quot; + tmpCh End If next col.code = exaStr next next end sub  搞定\n","id":14,"section":"posts","summary":"从数据库工具（比如：navicat）中导出表结构sql。 将sql导入到powerDesigner里。 File → Reverse Engineer → Database选中导出的表结","tags":["工具"],"title":"PowerDesigner行列转换脚本","uri":"https://cens7.github.io/2019/08/powerdesigner%E8%A1%8C%E5%88%97%E8%BD%AC%E6%8D%A2%E8%84%9A%E6%9C%AC/","year":"2019"},{"content":"背景 随着业务发展，订单线上数据已到达每日200万+，需要提前对订单做分库分表。结合市面上解决方案，决定采用sharding。sharding支持只分库，只分表，分库并分表。针对订单业务，我采用的是分库并分表。\n使用  sharding官网有很清晰的教程，本文是对使用过程中问题的一个记录。\n 我是用的是javaBean的配置形式，也支持yaml与properties，因人而异。\n1. 配置分库算法 public class OrderDatabaseAlgorithm implements PreciseShardingAlgorithm\u0026lt;String\u0026gt; { @Override public String doSharding(Collection\u0026lt;String\u0026gt; databaseNames, PreciseShardingValue\u0026lt;String\u0026gt; shardingValue) { String value = shardingValue.getValue(); // 将数据库分为order_0 ~ order_15 16个数据库 String key = String.valueOf(value.hashCode() \u0026amp; 15); String dsName = \u0026quot;\u0026quot;; for (String each : databaseNames) { if (each.endsWith(key)) { dsName = each; break; } } return dsName; } }  2. 配置分表算法 public class OrderTableAlgorithm implements PreciseShardingAlgorithm\u0026lt;String\u0026gt; { @Override public String doSharding(Collection\u0026lt;String\u0026gt; availableTargetNames, PreciseShardingValue\u0026lt;String\u0026gt; preciseShardingValue) { String value = preciseShardingValue.getValue(); // 将order表分为order_0 ~ order_127 128张表 String key = String.valueOf(value.hashCode() \u0026amp; 127); return preciseShardingValue.getLogicTableName() + \u0026quot;_\u0026quot; + key; } }  我将订单根据分片键分为128张表，16个库。 128*16=2048张表\n3. 数据库配置类 @Data public class ShardingSliceProperties { private String driverClassName; private String jdbcUrl; private String username; private String password; // 分片数据库 private String sliceDatabase; // 分片表 private String sliceTable; // 数据库分片键 private String sliceDatabaseKey; // 表分片键 private String sliceTableKey; }  4. 配置分库分表规则，并注入数据源 @Configuration public class ShardingConfig { @Bean public DataSource getShardingDataSource(ShardingSliceProperties shardingSliceProperties) throws SQLException { ShardingRuleConfiguration shardingRuleConfig = new ShardingRuleConfiguration(); TableRuleConfiguration tableRuleConfiguration = new TableRuleConfiguration(shardingSliceProperties.getSliceTable(), shardingSliceProperties.getSliceDatabase() + \u0026quot;_${0..15}.\u0026quot; + shardingSliceProperties.getSliceTable() + \u0026quot;_${0..127}\u0026quot;); // 设置表规则 shardingRuleConfig.getTableRuleConfigs().add(tableRuleConfiguration); // 设置分库规则 shardingRuleConfig.setDefaultDatabaseShardingStrategyConfig(new StandardShardingStrategyConfiguration( shardingSliceProperties.getSliceDatabaseKey(), new OrderDatabaseAlgorithm())); // 设置分表规则 shardingRuleConfig.setDefaultTableShardingStrategyConfig(new StandardShardingStrategyConfiguration( shardingSliceProperties.getSliceTableKey(), new OrderTableAlgorithm())); // 配置数据源 Map\u0026lt;String, DataSource\u0026gt; dataSourceMap = new HashMap\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; 16; i++) { HikariConfig hikariConfig = new HikariConfig(); hikariConfig.setDriverClassName(shardingSliceProperties.getDriverClassName()); hikariConfig.setJdbcUrl(shardingSliceProperties.getJdbcUrl() + \u0026quot;/\u0026quot; + shardingSliceProperties.getSliceDatabase() + \u0026quot;_\u0026quot; + i); hikariConfig.setUsername(shardingSliceProperties.getUsername()); hikariConfig.setPassword(shardingSliceProperties.getPassword()); hikariConfig.setMaximumPoolSize(25); hikariConfig.setMinimumIdle(5); HikariDataSource hikariDataSource = new HikariDataSource(hikariConfig); dataSourceMap.put(shardingSliceProperties.getSliceDatabase() + \u0026quot;_\u0026quot; + i, hikariDataSource); } Properties props = new Properties(); // 设置显示sql props.put(ShardingPropertiesConstant.SQL_SHOW.getKey(), String.valueOf(Boolean.TRUE)); return ShardingDataSourceFactory.createDataSource(dataSourceMap, shardingRuleConfig, props); } }  启动一下：\n2019-07-31 20:23:43.153 INFO o.a.c.core.StandardService log:173 Starting service [Tomcat] 2019-07-31 20:23:43.153 INFO o.a.catalina.core.StandardEngine log:173 Starting Servlet engine: [Apache Tomcat/9.0.21] 2019-07-31 20:23:43.269 INFO o.a.c.c.C.[.[localhost].[/] log:173 Initializing Spring embedded WebApplicationContext 2019-07-31 20:23:43.269 INFO o.s.web.context.ContextLoader prepareWebApplicationContext:283 Root WebApplicationContext: initialization completed in 2531 ms 2019-07-31 20:23:43.710 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:80 HikariPool-1 - Starting... 2019-07-31 20:23:43.867 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:82 HikariPool-1 - Start completed. 2019-07-31 20:23:43.868 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:80 HikariPool-2 - Starting... 2019-07-31 20:23:43.916 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:82 HikariPool-2 - Start completed. 2019-07-31 20:23:43.917 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:80 HikariPool-3 - Starting... 2019-07-31 20:23:43.939 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:82 HikariPool-3 - Start completed. 2019-07-31 20:23:43.939 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:80 HikariPool-4 - Starting... 2019-07-31 20:23:44.166 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:82 HikariPool-4 - Start completed. 2019-07-31 20:23:44.166 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:80 HikariPool-5 - Starting... 2019-07-31 20:23:44.192 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:82 HikariPool-5 - Start completed. 2019-07-31 20:23:44.193 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:80 HikariPool-6 - Starting... 2019-07-31 20:23:44.216 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:82 HikariPool-6 - Start completed. 2019-07-31 20:23:44.217 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:80 HikariPool-7 - Starting... 2019-07-31 20:23:44.239 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:82 HikariPool-7 - Start completed. 2019-07-31 20:23:44.239 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:80 HikariPool-8 - Starting... 2019-07-31 20:23:44.262 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:82 HikariPool-8 - Start completed. 2019-07-31 20:23:44.262 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:80 HikariPool-9 - Starting... 2019-07-31 20:23:44.284 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:82 HikariPool-9 - Start completed. 2019-07-31 20:23:44.285 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:80 HikariPool-10 - Starting... 2019-07-31 20:23:44.304 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:82 HikariPool-10 - Start completed. 2019-07-31 20:23:44.305 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:80 HikariPool-11 - Starting... 2019-07-31 20:23:44.330 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:82 HikariPool-11 - Start completed. 2019-07-31 20:23:44.330 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:80 HikariPool-12 - Starting... 2019-07-31 20:23:44.349 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:82 HikariPool-12 - Start completed. 2019-07-31 20:23:44.350 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:80 HikariPool-13 - Starting... 2019-07-31 20:23:44.377 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:82 HikariPool-13 - Start completed. 2019-07-31 20:23:44.377 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:80 HikariPool-14 - Starting... 2019-07-31 20:23:44.400 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:82 HikariPool-14 - Start completed. 2019-07-31 20:23:44.401 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:80 HikariPool-15 - Starting... 2019-07-31 20:23:44.424 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:82 HikariPool-15 - Start completed. 2019-07-31 20:23:44.425 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:80 HikariPool-16 - Starting... 2019-07-31 20:23:44.448 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:82 HikariPool-16 - Start completed. 2019-07-31 20:23:44.792 INFO o.a.s.c.c.l.ConfigurationLogger log:134 ShardingRuleConfiguration defaultDatabaseStrategy: standard: preciseAlgorithmClassName: com.aduer.pay.order.config.OrderDatabaseAlgorithm shardingColumn: merchant_no defaultTableStrategy: standard: preciseAlgorithmClassName: com.aduer.pay.order.config.OrderTableAlgorithm shardingColumn: merchant_no tables: order: actualDataNodes: pay-order_${0..15}.order_${0..127} logicTable: order 2019-07-31 20:23:44.793 INFO o.a.s.c.c.l.ConfigurationLogger log:134 Properties sql.show: 'true'  看日志，正确加载了数据源与数据表，测试一下，正常并通过。搞定。\n以上。\n","id":15,"section":"posts","summary":"背景 随着业务发展，订单线上数据已到达每日200万+，需要提前对订单做分库分表。结合市面上解决方案，决定采用sharding。sharding","tags":["Java","数据库","分库分表"],"title":"ShardingSphere使用心得","uri":"https://cens7.github.io/2019/07/shardingsphere%E4%BD%BF%E7%94%A8%E5%BF%83%E5%BE%97/","year":"2019"},{"content":"IO,NIO,AIO 学习与总结 Java 中的 BIO、NIO和 AIO 理解为是 Java 语言对操作系统的各种 IO 模型的封装。程序员在使用这些 API 的时候，不需要关心操作系统层面的知识，也不需要根据不同操作系统编写不同的代码。只需要使用Java的API就可以了。\n在讲 BIO,NIO,AIO 之前先来回顾一下这样几个概念：同步与异步，阻塞与非阻塞。\n关于同步和异步的概念解读困扰着很多程序员，大部分的解读都会带有自己的一点偏见。参考了 Stackoverflow相关问题后对原有答案进行了进一步完善：\n When you execute something synchronously, you wait for it to finish before moving on to another task. When you execute something asynchronously, you can move on to another task before it finishes.\n  当你同步执行某项任务时，你需要等待其完成才能继续执行其他任务。当你异步执行某些操作时，你可以在完成另一个任务之前继续进行。\n  同步：两个同步任务相互依赖，并且一个任务必须以依赖于另一任务的某种方式执行。 比如在A-\u0026gt;B事件模型中，你需要先完成 A 才能执行B。 再换句话说，同步调用种被调用者未处理完请求之前，调用不返回，调用者会一直等待结果的返回。 异步： 两个异步的任务完全独立的，一方的执行不需要等待另外一方的执行。再换句话说，异步调用种一调用就返回结果不需要等待结果返回，当结果返回的时候通过回调函数或者其他方式拿着结果再做相关事情。  阻塞和非阻塞  阻塞： 阻塞就是发起一个请求，调用者一直等待请求结果返回，也就是当前线程会被挂起，无法从事其他任务，只有当条件就绪才能继续。 非阻塞： 非阻塞就是发起一个请求，调用者不用一直等着结果返回，可以先去干其他事情。  如何区分 “同步/异步 ”和 “阻塞/非阻塞” 呢？同步/异步是从行为角度描述事物的，而阻塞和非阻塞描述的当前事物的状态（等待调用结果时的状态）。\n1. BIO (Blocking I/O) 同步阻塞I/O模式，数据的读取写入必须阻塞在一个线程内等待其完成。\n1.1 传统 BIO BIO通信（一请求一应答）模型图如下：采用BIO 通信模型的服务端，通常由一个独立的 Acceptor 线程负责监听客户端的连接。我们一般通过在while(true) 循环中服务端会调用 accept() 方法等待接收客户端的连接的方式监听请求，请求一旦接收到一个连接请求，就可以建立通信套接字在这个通信套接字上进行读写操作，此时不能再接收其他客户端连接请求，只能等待同当前连接的客户端的操作执行完成， 不过可以通过多线程来支持多个客户端的连接，如上图所示。\n如果要让BIO 通信模型能够同时处理多个客户端请求，就必须使用多线程（主要原因是socket.accept()、socket.read()、socket.write() 涉及的三个主要函数都是同步阻塞的），也就是说它在接收到客户端连接请求之后为每个客户端创建一个新的线程进行链路处理，处理完成之后，通过输出流返回应答给客户端，线程销毁。这就是典型的一请求一应答通信模型 。我们可以设想一下如果这个连接不做任何事情的话就会造成不必要的线程开销，不过可以通过线程池机制 改善，线程池还可以让线程的创建和回收成本相对较低。使用FixedThreadPool 可以有效的控制了线程的最大数量，保证了系统有限的资源的控制，实现了N(客户端请求数量):M(处理客户端请求的线程数量)的伪异步I/O模型（N 可以远远大于 M），下面一节\u0026quot;伪异步 BIO\u0026quot;中会详细介绍到。\n我们再设想一下当客户端并发访问量增加后这种模型会出现什么问题？\n在 Java 虚拟机中，线程是宝贵的资源，线程的创建和销毁成本很高，除此之外，线程的切换成本也是很高的。尤其在 Linux 这样的操作系统中，线程本质上就是一个进程，创建和销毁线程都是重量级的系统函数。如果并发访问量增加会导致线程数急剧膨胀可能会导致线程堆栈溢出、创建新线程失败等问题，最终导致进程宕机或者僵死，不能对外提供服务。\n1.2 伪异步 IO 为了解决同步阻塞I/O面临的一个链路需要一个线程处理的问题，后来有人对它的线程模型进行了优化一一一后端通过一个线程池来处理多个客户端的请求接入，形成客户端个数M：线程池最大线程数N的比例关系，其中M可以远远大于N.通过线程池可以灵活地调配线程资源，设置线程的最大值，防止由于海量并发接入导致线程耗尽。\n伪异步IO模型图：采用线程池和任务队列可以实现一种叫做伪异步的 I/O 通信框架，它的模型图如上图所示。当有新的客户端接入时，将客户端的 Socket 封装成一个Task（该任务实现java.lang.Runnable接口）投递到后端的线程池中进行处理，JDK 的线程池维护一个消息队列和 N 个活跃线程，对消息队列中的任务进行处理。由于线程池可以设置消息队列的大小和最大线程数，因此，它的资源占用是可控的，无论多少个客户端并发访问，都不会导致资源的耗尽和宕机。\n伪异步I/O通信框架采用了线程池实现，因此避免了为每个请求都创建一个独立线程造成的线程资源耗尽问题。不过因为它的底层仍然是同步阻塞的BIO模型，因此无法从根本上解决问题。\n1.3 代码示例 下面代码中演示了BIO通信（一请求一应答）模型。我们会在客户端创建多个线程依次连接服务端并向其发送\u0026quot;当前时间+:hello world\u0026rdquo;，服务端会为每个客户端线程创建一个线程来处理。代码原地址如下：https://www.jianshu.com/p/a4e03835921a 客户端public class IOClient { public static void main(String[] args) { // TODO 创建多个线程，模拟多个客户端连接服务端 new Thread(() -\u0026gt; { try { Socket socket = new Socket(\u0026quot;127.0.0.1\u0026quot;, 3333); while (true) { try { socket.getOutputStream().write((new Date() + \u0026quot;: hello world\u0026quot;).getBytes()); Thread.sleep(2000); } catch (Exception e) { } } } catch (IOException e) { } }).start(); } }  服务端public class IOServer { public static void main(String[] args) throws IOException { // TODO 服务端处理客户端连接请求 ServerSocket serverSocket = new ServerSocket(3333); // 接收到客户端连接请求之后为每个客户端创建一个新的线程进行链路处理 new Thread(() -\u0026gt; { while (true) { try { // 阻塞方法获取新的连接 Socket socket = serverSocket.accept(); // 每一个新的连接都创建一个线程，负责读取数据 new Thread(() -\u0026gt; { try { int len; byte[] data = new byte[1024]; InputStream inputStream = socket.getInputStream(); // 按字节流方式读取数据 while ((len = inputStream.read(data)) != -1) { System.out.println(new String(data, 0, len)); } } catch (IOException e) { } }).start(); } catch (IOException e) { } } }).start(); } }  1.4 总结 在活动连接数不是特别高（小于单机1000）的情况下，这种模型是比较不错的，可以让每一个连接专注于自己的 I/O 并且编程模型简单，也不用过多考虑系统的过载、限流等问题。线程池本身就是一个天然的漏斗，可以缓冲一些系统处理不了的连接或请求。但是，当面对十万甚至百万级连接的时候，传统的 BIO 模型是无能为力的。因此，我们需要一种更高效的 I/O 处理模型来应对更高的并发量。\n2. NIO (New I/O) 2.1 NIO 简介 NIO是一种同步非阻塞的I/O模型，在Java 1.4 中引入了 NIO 框架，对应 java.nio 包，提供了 Channel , Selector，Buffer等抽象。\nNIO中的N可以理解为Non-blocking，不单纯是New。它支持面向缓冲的，基于通道的I/O操作方法。 NIO提供了与传统BIO模型中的 Socket 和 ServerSocket 相对应的 SocketChannel 和 ServerSocketChannel 两种不同的套接字通道实现,两种通道都支持阻塞和非阻塞两种模式。阻塞模式使用就像传统中的支持一样，比较简单，但是性能和可靠性都不好；非阻塞模式正好与之相反。对于低负载、低并发的应用程序，可以使用同步阻塞I/O来提升开发速率和更好的维护性；对于高负载、高并发的（网络）应用，应使用 NIO 的非阻塞模式来开发。\n2.2 NIO的特性/NIO与IO区别 如果是在面试中回答这个问题，我觉得首先肯定要从 NIO 流是非阻塞 IO 而 IO 流是阻塞 IO 说起。然后，可以从 NIO 的3个核心组件/特性为 NIO 带来的一些改进来分析。如果，你把这些都回答上了我觉得你对于 NIO 就有了更为深入一点的认识，面试官问到你这个问题，你也能很轻松的回答上来了。\n1)Non-blocking IO（非阻塞IO） IO流是阻塞的，NIO流是不阻塞的。Java NIO使我们可以进行非阻塞IO操作。比如说，单线程中从通道读取数据到buffer，同时可以继续做别的事情，当数据读取到buffer中后，线程再继续处理数据。写数据也是一样的。另外，非阻塞写也是如此。一个线程请求写入一些数据到某通道，但不需要等待它完全写入，这个线程同时可以去做别的事情。\nJava IO的各种流是阻塞的。这意味着，当一个线程调用 read() 或 write() 时，该线程被阻塞，直到有一些数据被读取，或数据完全写入。该线程在此期间不能再干任何事情了\n2)Buffer(缓冲区) IO 面向流(Stream oriented)，而 NIO 面向缓冲区(Buffer oriented)。Buffer是一个对象，它包含一些要写入或者要读出的数据。在NIO类库中加入Buffer对象，体现了新库与原I/O的一个重要区别。在面向流的I/O中·可以将数据直接写入或者将数据直接读到 Stream 对象中。虽然 Stream 中也有 Buffer 开头的扩展类，但只是流的包装类，还是从流读到缓冲区，而 NIO 却是直接读到 Buffer 中进行操作。\n在NIO厍中，所有数据都是用缓冲区处理的。在读取数据时，它是直接读到缓冲区中的; 在写入数据时，写入到缓冲区中。任何时候访问NIO中的数据，都是通过缓冲区进行操作。\n最常用的缓冲区是 ByteBuffer,一个 ByteBuffer 提供了一组功能用于操作 byte 数组。除了ByteBuffer,还有其他的一些缓冲区，事实上，每一种Java基本类型（除了Boolean类型）都对应有一种缓冲区。\n3)Channel (通道) NIO 通过Channel（通道） 进行读写。通道是双向的，可读也可写，而流的读写是单向的。无论读写，通道只能和Buffer交互。因为 Buffer，通道可以异步地读写。\n4)Selector (选择器) NIO有选择器，而IO没有。选择器用于使用单个线程处理多个通道。因此，它需要较少的线程来处理这些通道。线程之间的切换对于操作系统来说是昂贵的。 因此，为了提高系统效率选择器是有用的。2.3 NIO 读数据和写数据方式 通常来说NIO中的所有IO都是从 Channel（通道） 开始的。\n 从通道进行数据读取 ：创建一个缓冲区，然后请求通道读取数据。 从通道进行数据写入 ：创建一个缓冲区，填充数据，并要求通道写入数据。  数据读取和写入操作图示：2.4 NIO核心组件简单介绍 NIO 包含下面几个核心的组件：\n Channel(通道) Buffer(缓冲区) Selector(选择器)  整个NIO体系包含的类远远不止这三个，只能说这三个是NIO体系的“核心API”。\n2.5 代码示例 public class NIOServer { public static void main(String[] args) throws IOException { // 1. serverSelector负责轮询是否有新的连接，服务端监测到新的连接之后，不再创建一个新的线程， // 而是直接将新连接绑定到clientSelector上，这样就不用 IO 模型中 1w 个 while 循环在死等 Selector serverSelector = Selector.open(); // 2. clientSelector负责轮询连接是否有数据可读 Selector clientSelector = Selector.open(); new Thread(() -\u0026gt; { try { // 对应IO编程中服务端启动 ServerSocketChannel listenerChannel = ServerSocketChannel.open(); listenerChannel.socket().bind(new InetSocketAddress(3333)); listenerChannel.configureBlocking(false); listenerChannel.register(serverSelector, SelectionKey.OP_ACCEPT); while (true) { // 监测是否有新的连接，这里的1指的是阻塞的时间为 1ms if (serverSelector.select(1) \u0026gt; 0) { Set\u0026lt;SelectionKey\u0026gt; set = serverSelector.selectedKeys(); Iterator\u0026lt;SelectionKey\u0026gt; keyIterator = set.iterator(); while (keyIterator.hasNext()) { SelectionKey key = keyIterator.next(); if (key.isAcceptable()) { try { // (1) 每来一个新连接，不需要创建一个线程，而是直接注册到clientSelector SocketChannel clientChannel = ((ServerSocketChannel) key.channel()).accept(); clientChannel.configureBlocking(false); clientChannel.register(clientSelector, SelectionKey.OP_READ); } finally { keyIterator.remove(); } } } } } } catch (IOException ignored) { } }).start(); new Thread(() -\u0026gt; { try { while (true) { // (2) 批量轮询是否有哪些连接有数据可读，这里的1指的是阻塞的时间为 1ms if (clientSelector.select(1) \u0026gt; 0) { Set\u0026lt;SelectionKey\u0026gt; set = clientSelector.selectedKeys(); Iterator\u0026lt;SelectionKey\u0026gt; keyIterator = set.iterator(); while (keyIterator.hasNext()) { SelectionKey key = keyIterator.next(); if (key.isReadable()) { try { SocketChannel clientChannel = (SocketChannel) key.channel(); ByteBuffer byteBuffer = ByteBuffer.allocate(1024); // (3) 面向 Buffer clientChannel.read(byteBuffer); byteBuffer.flip(); System.out.println( Charset.defaultCharset().newDecoder().decode(byteBuffer).toString()); } finally { keyIterator.remove(); key.interestOps(SelectionKey.OP_READ); } } } } } } catch (IOException ignored) { } }).start(); } }  为什么大家都不愿意用 JDK 原生 NIO 进行开发呢？从上面的代码中大家都可以看出来，是真的难用！除了编程复杂、编程模型难之外，它还有以下让人诟病的问题：\n JDK 的 NIO 底层由 epoll 实现，该实现饱受诟病的空轮询 bug 会导致 cpu 飙升 100% 项目庞大之后，自行实现的 NIO 很容易出现各类 bug，维护成本较高，上面这一坨代码我都不能保证没有 bug  Netty 的出现很大程度上改善了 JDK 原生 NIO 所存在的一些让人难以忍受的问题。\n3. AIO (Asynchronous I/O) AIO 也就是 NIO 2。在 Java 7 中引入了 NIO 的改进版 NIO 2,它是异步非阻塞的IO模型。异步 IO 是基于事件和回调机制实现的，也就是应用操作之后会直接返回，不会堵塞在那里，当后台处理完成，操作系统会通知相应的线程进行后续的操作。\nAIO 是异步IO的缩写，虽然 NIO 在网络操作中，提供了非阻塞的方法，但是 NIO 的 IO 行为还是同步的。对于 NIO 来说，我们的业务线程是在 IO 操作准备好时，得到通知，接着就由这个线程自行进行 IO 操作，IO操作本身是同步的。（除了 AIO 其他的 IO 类型都是同步的，这一点可以从底层IO线程模型解释，推荐一篇文章：《漫话：如何给女朋友解释什么是Linux的五种IO模型？》 ）\n参考 《Netty 权威指南》第二版 https://zhuanlan.zhihu.com/p/23488863 (美团技术团队)  ","id":16,"section":"posts","summary":"IO,NIO,AIO 学习与总结 Java 中的 BIO、NIO和 AIO 理解为是 Java 语言对操作系统的各种 IO 模型的封装。程序员在使用这些 API 的时候，不需要关心操作系统层面的知识，也不","tags":["Java"],"title":"NIO_AIO_BIO学习与总结","uri":"https://cens7.github.io/2019/05/nio_aio_bio%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%80%BB%E7%BB%93/","year":"2019"},{"content":"问题 springCloud整合的rabbitmq， 在消费端设置了group，通常情况消费端只消费了一次，偶尔碰到一次 mq被消费两次。  解决 添加groupId 分组  ","id":17,"section":"posts","summary":"问题 springCloud整合的rabbitmq， 在消费端设置了group，通常情况消费端只消费了一次，偶尔碰到一次 mq被消费两次。 解决 添加","tags":["Java","SpringCloud","问题"],"title":"SpringCloud中rabbitmq被消费多次","uri":"https://cens7.github.io/2018/06/springcloud%E4%B8%ADrabbitmq%E8%A2%AB%E6%B6%88%E8%B4%B9%E5%A4%9A%E6%AC%A1/","year":"2018"},{"content":"lambda基本使用 1.将List转成Map\u0026lt;Id,Person\u0026gt;  Map\u0026lt;Id,Person\u0026gt; map = list.parallelStream(). collect(Collectors.toMap(Person::getId, p -\u0026gt; p));\n 2.将List按照sex分组  Map\u0026lt;String,Person\u0026gt; map = list.parallelStream(). collect(Collectors.groupingBy(Person::getSex));\n 3.取出List的平均score  dobble avg = list.parallelStream(). mapToDouble(p -\u0026gt; p.getScore()).average().getAsDouble();\n 4.取出List中id为10的学生  Optionalop = list.parallelStream().filter(p -\u0026gt; p.getId().equals(10)).findFirst(); Person p = op.get();\n 5.取出List中所有的id  Listids = list.parallelSream().map(Person::getId).collect(Collectors.toList());\n 6.根据score,取前100名 （降序）  Listpersons =list.parallelStream(). sorted(Comparator.comparing(Person::getScore()).reversed()). limit(100).collect(Collectors.toList());//使用guava ListpeopleList1 = Ordering.natural().onResultOf(People::getId).sortedCopy(peopleList);\n 7.取出分数最高的学生信息  Person person = list.parallelStream().max(Comparator.comparing(Person::getScore()).get();\n// 只能取出最小的ID 不能取出整个对象\nInteger min = Ordering.natural().reverse().min(Iterables.transform(peopleList, People::getId));\n 8.算所有学生的分数  Long sum = list.parallelStream().map(Person::getScore).reduce((x1,x2) -\u0026gt; x1+x2).get();\n 9.求所有金钱总和  BigDecimal money = list.parallelStream().map(Person::getMoney).reduce(BigDecimal::add).get();\n 10.取出两个不同List对象中相等的Id   11.剔除List中金钱一样的对象   Collectionvalues = list.parallelStream(). collect(Collectors.toMap(Person::getMoney, p -\u0026gt; p , (p,q) -\u0026gt; p)).values();       12.将List转成Map\u0026lt;Long,List\u0026gt;。 (如果需要，可以转成Map\u0026lt;String,List\u0026gt;等等)\n Map\u0026lt;Long, List\u0026gt; result = listHello.stream().collect(Collectors.groupingBy(Person::getId));\n 13.CompletableFuture结合lambda异步执行并汇总   14.对象转map  Map\u0026lt;String, String\u0026gt; collect = privilegeObjList.stream().collect(Collectors.toMap(PlatformPrivilegeF::getModuleNo, PlatformPrivilegeF::getPrivilege));\n 15.把对象的moduleNo当Map的key，privilege当map的value List集合元素。  Map\u0026lt;String, List\u0026gt; map = privilegeObjList.stream().collect( Collectors.groupingBy(PlatformPrivilegeF::getModuleNo, Collectors.mapping(PlatformPrivilegeF::getPrivilege, Collectors.toList())));\n ","id":18,"section":"posts","summary":"lambda基本使用 1.将List转成Map\u0026lt;Id,Person\u0026gt; Map\u0026lt;Id,Person\u0026gt; map = list.parallelStream(). collect(Collectors.toMap(Person::getId, p -\u0026gt; p)); 2.将List按照sex分组 Map\u0026lt;String,Person\u0026gt; map = list.parallelStream(). collect(Collectors.groupingBy(Person::getSex)); 3.取出","tags":["Java","lambda"],"title":"Lambda基本使用","uri":"https://cens7.github.io/2017/04/lambda%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/","year":"2017"},{"content":"基本设置 关闭默认打开工程：关闭大小写敏感：换行显示10个文件选项卡：常用插件  lombok 注解 mybatis plugin maven helper String Manipulation 字符串处理 Translation 翻译  ","id":19,"section":"posts","summary":"基本设置 关闭默认打开工程：关闭大小写敏感：换行显示10个文件选项卡：常用插件 lombok 注解 mybatis plugin maven helper String Manipulation 字符串处理 Translation 翻译","tags":["idea"],"title":"idea基本设置","uri":"https://cens7.github.io/2016/12/idea%E5%9F%BA%E6%9C%AC%E8%AE%BE%E7%BD%AE/","year":"2016"},{"content":"位逻辑运算符 与运算（\u0026amp;） 与运算：两个运算数比较位都是 1，则结果为 1，否则为 0。例如：5 \u0026amp; 3 = 1\n0000 0000 0000 0000 0000 0000 0000 0101 5 转换为二进制 0000 0000 0000 0000 0000 0000 0000 0011 3 转换为二进制 0000 0000 0000 0000 0000 0000 0000 0001 换算成 10 进制为 1  或运算（|） 或运算：两个运算数比较位有一个为 1，则结果为 1，否则为 0。例如：5 | 3 = 7\n0000 0000 0000 0000 0000 0000 0000 0101 5 转换为二进制 0000 0000 0000 0000 0000 0000 0000 0011 3 转换为二进制 0000 0000 0000 0000 0000 0000 0000 0111 换算成 10 进制为 7  异或运算（^） 异或运算：两个运算数比较位不同时，其结果是 1，否则为 0。例如：5 ^ 3 = 6\n0000 0000 0000 0000 0000 0000 0000 0101 5 转换为二进制 0000 0000 0000 0000 0000 0000 0000 0011 3 转换为二进制 0000 0000 0000 0000 0000 0000 0000 0110 换算成 10 进制为 6  非运算（~） 非运算：也叫做补，一元运算符，对其运算数的每一位取反。例如：~5 = -6\n0000 0000 0000 0000 0000 0000 0000 0101 5 转换为二进制 1111 1111 1111 1111 1111 1111 1111 1010 取非后的原码 1000 0000 0000 0000 0000 0000 0000 0110 转换补码，换算成 10 进制为 -6  ####其它\n  Java 中整数类型（byte、short、int 和 long）在内存中是以有符号的二进制补码表示。所以位运算时，首先要转换为原码。\n  补码转原码：补码转原码和原码转补码的方法是一样的，取反 + 1（补码的补码是原码）。\n  当位运算数是 byte 和 short 类型时，将自动把这些类型扩大为 int 型（32 位）。\n  计算出 n 位二进制数所能表示的最大十进制数位移算法：-1L ^ (-1L \u0026laquo; n) 或 ~(-1L \u0026laquo; n)。\n  byte 和 int 相互转换\n  int i = 234; byte b = (byte) i; // 结果：b = -22 // 转换过程： // 0000 0000 0000 0000 0000 0000 1110 1010 # int 234 的补码（与原码相等） // 1110 1010 # byte 低位截取 // 1001 0110 # 求得补码，转为 10 进制为 -22 int x = b ; // 结果为：x = -22；8 位 byte 的转 32 的 int，值不变。 int y = b \u0026amp; 0xff; // 结果为：x = 234； 可以通过将其和 0xff 进行位与（\u0026amp;）得到它的无符值 // 转换过程： // 1001 0110 # byte -22 的原码 // 1000 0000 0000 0000 0000 0000 0001 0110 # int -22 的原码 // 1111 1111 1111 1111 1111 1111 1110 1010 # int -22 补码 // 0000 0000 0000 0000 0000 0000 1111 1111 # 0xff 的二进制数 // 0000 0000 0000 0000 0000 0000 1110 1010 # 和 0xff 进与操作的结果，转换为 10 进制为 234  ","id":20,"section":"posts","summary":"位逻辑运算符 与运算（\u0026amp;） 与运算：两个运算数比较位都是 1，则结果为 1，否则为 0。例如：5 \u0026amp; 3 = 1 0000 0000 0000 0000 0000 0000 0000 0101 5 转换为二进制 0000 0000 0000 0000","tags":["数据结构"],"title":"Java位运算2_位运算","uri":"https://cens7.github.io/2016/02/java%E4%BD%8D%E8%BF%90%E7%AE%972_%E4%BD%8D%E8%BF%90%E7%AE%97/","year":"2016"},{"content":"左移运算（\u0026laquo;） value \u0026lt;\u0026lt; num   num 指定要移位值；value 移动的位数。\n 将左操作数（value）转为二进制数后向左边移动 num 位，并且在低位补 0，高位丢弃。\n例如：5 \u0026laquo; 2\n0000 0000 0000 0000 0000 0000 0000 0101 5 的补码（同原码） 0000 0000 0000 0000 0000 0000 0001 0100 左移 2 位后，低位补 0。换算成 10 进制为 20  如果移动的位数超过了该类型的最大位数，那么编译器会对移动的位数取模。如：对 int 类型（最大位数 32）的数值移动 33 位，实际上只移动了 33 % 32 = 1 位。\n 注：n 位二进制，最高位为符号位，因此表示的数值范围：−2(𝑛−1) —— 2(𝑛−1)−1，所以模为：2(𝑛−1)。\n 在数字没有溢出的前提下，对于正数和负数，左移一位都相当于乘以 2 的 1 次方，左移 n 位就相当于乘以 2 的 n 次方。如：5 \u0026laquo; 2 相当于 5∗22=20。\n如果移进高阶位（int 31 或 long 63 位），那么该值将变为负值。如：1 \u0026laquo; 31 = -2147483648\n右移运算（\u0026raquo;） value \u0026gt;\u0026gt; num   num 指定要移位值；value 移动的位数。\n 将左操作数（value）转为二进制数后向右边移动 num 位，符号位不变，高位补上符号位（若左操作数是正数，则高位补 0，若左操作数是负数，则高位补 1），低位丢弃。\n右移时，被移走的最高位（最左边的位）由原来最高位的数字补充，这叫做符号位扩展（保留符号位）（sign extension），在进行右移操作时用来保持负数的符号。\n例如：7 \u0026raquo; 2\n0000 0000 0000 0000 0000 0000 0000 0111 7 的补码（同原码） 0000 0000 0000 0000 0000 0000 0000 0001 右移 2 位后，高位补 0。换算成 10 进制为 1  例如：-7 \u0026raquo; 2\n1000 0000 0000 0000 0000 0000 0000 0111 -7 的原码 1111 1111 1111 1111 1111 1111 1111 1000 -7 的反码 1111 1111 1111 1111 1111 1111 1111 1001 -7 的补码 1111 1111 1111 1111 1111 1111 1111 1110 右移 2 位后，高位补 1 1000 0000 0000 0000 0000 0000 0000 0010 补码转原码。换算成 10 进制为 -2  正数右移 n 位相当于除以 2 的 n 次方并且舍弃了余数。如：7 \u0026raquo; 2 相当于： 7/22=1。\n负数右移 n 位相当于除以 2 的 n 次方，如果有余数 -1。如：-7 \u0026raquo; 2 相当于： 7∗22−1=−2。\n例子：\npublic static void main(String[] args) { // 左移 int i = 16; // 在二进制i的右边加两个零，也就是二进制乘以100 // 100换算成10进制，乘以4 // 也可能看作是乘以2的2次幂 int i1 = i \u0026lt;\u0026lt; 2; int i2 = i * (2 * 2); System.out.println(\u0026quot;i1 = \u0026quot; + i1 + \u0026quot;, i2 = \u0026quot; + i2); // 在二进制i的右边加三个零，也就是二进制乘以1000 // 1000换算成10进制，乘以8 // 也可能看作是乘以2的3次幂 int i3 = i \u0026lt;\u0026lt; 3; int i4 = i * (2 * 2 * 2); System.out.println(\u0026quot;i3 = \u0026quot; + i3 + \u0026quot;, i4 = \u0026quot; + i4); // -------------------------------------------------------- // 右移 int j = 16; // 在二进制i的右边减少两个零，也就是二进制除以100 // 100换算成10进制，除以4 // 也可能看作是除以2的2次幂 int j1 = j \u0026gt;\u0026gt; 2; int j2 = i / (2 * 2); System.out.println(\u0026quot;j1 = \u0026quot; + j1 + \u0026quot;, j2 = \u0026quot; + j2); }  无符号右移（\u0026raquo;\u0026gt;） value \u0026gt;\u0026gt;\u0026gt; num   num 指定要移位值；value 移动的位数。\n 将左操作数（value）转为二进制数后向右边移动 num 位，0 补最高位（忽略了符号位扩展）。\n无符号右移运算只是对 32 位和 64 位的值有意义。\n例如：-7 \u0026raquo;\u0026gt; 2\n1000 0000 0000 0000 0000 0000 0000 0111 -7 的原码 1111 1111 1111 1111 1111 1111 1111 1001 -7 的补码 0011 1111 1111 1111 1111 1111 1111 1110 右移 2 位后，高位补 0。换算成 10 进制为 1073741822  ","id":21,"section":"posts","summary":"左移运算（\u0026laquo;） value \u0026lt;\u0026lt; num num 指定要移位值；value 移动的位数。 将左操作数（value）转为二进制数后向左边移动 num 位，并且在低位补 0，","tags":["数据结构"],"title":"Java位运算1_左移、右移","uri":"https://cens7.github.io/2016/02/java%E4%BD%8D%E8%BF%90%E7%AE%971_%E5%B7%A6%E7%A7%BB%E5%8F%B3%E7%A7%BB/","year":"2016"},{"content":"广义表：  L=(a,b) L长度为2，深度为1\nL=(x,(a,b)）长度为2，深度为2\nL=(x,(a,b,c),y) 长度为3，深度为6\nL=(a,a,a,(a,\u0026hellip;))长度为4，深度为无穷大\n 无向图G5的邻接矩阵是： A1 ={0，1，1，1}\n{1，0，1，1}\n{1，1，0，0}\n{1，1，0，0}\n 有向图G6的邻接矩阵是：\n A2 = {0，1，0，0，0}\n{1，0，0，0，1}\n{0，1，0，1，0}\n{1，0，0，0，0}\n{0，0，0，1，0}\n  排序：内部排序：排序时不涉及数据的内、外存交换。适用于记录个数不很多的小文件。包括：插入排序、选择排序、交换排序、归并排序和分配排序。 外部排序：过程中要进行数据的内、外存交换。适用于记录个数太多，不能一次放到内存的大文件。     算法名 类别 平均 最好 最坏 辅助 稳定性     直接插入排序 插入排序 O(n²) O(n) O(n²) O(1) 稳定   希尔排序 插入排序 O(n^1.5) O(n) O(n²) O(1) 不稳定   简单选择排序 选择排序 O(n²) O(n²) O(n²) O(1) 不稳定   堆排序 选择排序 O(n㏒2n) O(n㏒2n) O(n㏒2n) O(1) 不稳定   冒泡排序 交换排序 O(n²) O(n) O(n²) O(1) 稳定   快速排序 交换排序 O(n㏒2n) O(n㏒2n) O(n²) O(n㏒2n) 不稳定   归并排序 归并排序 O(n㏒2n) O(n㏒2n) O(n㏒2n) O(1) 稳定   基数排序 基数排序 O(d(r+n)) O(d(rd+n)) O(d(r+n)) O(rd+n) 稳定     二叉树节点的度指父节点对应的下面孩子节点个数，最大为2。 BFS（Breadth-first Search）宽度优先搜索。先从根节点开始，搜索根节点左侧V1；搜索根节点右侧V2；搜索V1左侧V11；搜索V2右侧，当V2节点已经被V1搜索过，则V2停止。 DFS（Depth-first Search）深度优先搜索。先从根节点开始，搜索根节点左侧V1下面所有节点；搜索完再搜索根节点右侧V2所有节点。当V2节点已经被V1搜索过，则V2停止。 二路归并排序是把数组分成 n/2 +1个子数组，子数组内排序完成，在一直两两归并排序下去成一个数组。 图的广度优先遍历(BFS)类似于树的层次遍历。 图的深度优先遍历(DFS)类似于树的前序遍历。 直接插入排序后，可能未能选出一个元素放到其最终位置上。 快速排序、冒泡排序、希尔排序、堆排序原理。 二叉树等改路情况下平均查找长度等于= （∑(节点数量×节点个数)）÷所有节点个数。 堆排序是一种树形选择排序。 设线性表的长度为n，则顺序查找成功时的平均查找长度为 (n+1)/2。 抽象数据类型是指抽象数据的组织和与之相关的操作。 当三交矩阵的常数为0时，n阶三角矩阵的非零元素个数为n(n+1)/2。 有向图中的极大连通子图称作有向图的强连接分量。  ","id":22,"section":"posts","summary":"广义表： L=(a,b) L长度为2，深度为1 L=(x,(a,b)）长度为2，深度为2 L=(x,(a,b,c),y) 长度为3，深度为6 L=(a,a,a,(a,\u0026hellip;))长度为","tags":["数据结构"],"title":"数据结构学习笔记_1","uri":"https://cens7.github.io/2015/11/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_1/","year":"2015"}],"tags":[{"title":"acm","uri":"https://cens7.github.io/tags/acm/"},{"title":"docker","uri":"https://cens7.github.io/tags/docker/"},{"title":"Dubbo","uri":"https://cens7.github.io/tags/dubbo/"},{"title":"idea","uri":"https://cens7.github.io/tags/idea/"},{"title":"Java","uri":"https://cens7.github.io/tags/java/"},{"title":"Kotlin","uri":"https://cens7.github.io/tags/kotlin/"},{"title":"lambda","uri":"https://cens7.github.io/tags/lambda/"},{"title":"mybatis","uri":"https://cens7.github.io/tags/mybatis/"},{"title":"redis","uri":"https://cens7.github.io/tags/redis/"},{"title":"springboot","uri":"https://cens7.github.io/tags/springboot/"},{"title":"SpringCloud","uri":"https://cens7.github.io/tags/springcloud/"},{"title":"webSocket","uri":"https://cens7.github.io/tags/websocket/"},{"title":"xss","uri":"https://cens7.github.io/tags/xss/"},{"title":"分库分表","uri":"https://cens7.github.io/tags/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/"},{"title":"多线程","uri":"https://cens7.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"title":"安全","uri":"https://cens7.github.io/tags/%E5%AE%89%E5%85%A8/"},{"title":"工具","uri":"https://cens7.github.io/tags/%E5%B7%A5%E5%85%B7/"},{"title":"数据库","uri":"https://cens7.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"title":"数据结构","uri":"https://cens7.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"title":"架构","uri":"https://cens7.github.io/tags/%E6%9E%B6%E6%9E%84/"},{"title":"测试","uri":"https://cens7.github.io/tags/%E6%B5%8B%E8%AF%95/"},{"title":"配置中心","uri":"https://cens7.github.io/tags/%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83/"},{"title":"问题","uri":"https://cens7.github.io/tags/%E9%97%AE%E9%A2%98/"}]}