{"categories":[],"posts":[{"content":"\n","id":0,"section":"posts","summary":"","tags":["Java","多线程","协程"],"title":"ProjectLoom学习心得","uri":"https://cens7.github.io/2020/03/projectloom%E5%AD%A6%E4%B9%A0%E5%BF%83%E5%BE%97/","year":"2020"},{"content":"Netty-Socketio使用 1.添加依赖 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.corundumstudio.socketio\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;netty-socketio\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.7.18\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;  2.配置 2.1 配置 redisson 略，前面有redisson的博文，我介绍过。\n2.2 配置socketio的Configuration public Configuration getConfig(){ Configuration config = new Configuration(); config.setHostname(\u0026quot;localhost\u0026quot;); config.setPort(9092); InputStream ssl = WebSocketServer.class.getResourceAsStream(jksPath);//证书地址 config.setPort.setKeyStore(ssl); final SocketIOServer server = new SocketIOServer(config); }  2.3 注册监听器 注册连接监听器与断开监听器\nvoid addListener() { socketServer.addConnectListener(new ConnectListener() { @Override public void onConnect(SocketIOClient socketIOClient) { connectThreadPool.submit(new Runnable() { @Override public void run() { HandshakeData handshakeData = socketIOClient.getHandshakeData(); // 消息接收方 String system = handshakeData.getSingleUrlParam(HandshakeParamsDTO.FROM); socketIOClient.joinRoom(system); // 将用户信息存到缓存 } }); } }); socketServer.addDisconnectListener(new DisconnectListener() { @Override public void onDisconnect(SocketIOClient socketIOClient) { disconnectThreadPool.submit(new Runnable() { @Override public void run() { //从缓存删除用户信息 } }); } }); }  2.4 启动/断开服务  启动socketServer.start(); 断开socketServer.stop();  2.5 发消息 单个发送：\npublic void sendMessageToUser(WebSocketDataDTO message) { Packet packet = new Packet(PacketType.MESSAGE); packet.setData(message.getMessage()); String sessionId = redisHelper.getSessionIdOfUser(message); // 从缓存取出用户信息 if(!StringUtils.isBlank(sessionId)) { socketServer.getClient(UUID.fromString(sessionId)).send(packet, new AckCallback\u0026lt;AckResult\u0026gt;(AckResult.class) { @Override public void onSuccess(AckResult result) { } }); } }  广播发送：\npublic void sendRoomMessage(WebSocketDataDTO message) { if(StringUtils.isBlank(message.getTo())) { Packet packet = new Packet(PacketType.MESSAGE); packet.setData(message.getMessage()); socketServer.getRoomOperations(message.getTo()).send(packet); } }  ","id":1,"section":"posts","summary":"Netty-Socketio使用 1.添加依赖 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.corundumstudio.socketio\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;netty-socketio\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.7.18\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 2.配置 2.1 配置 redisson 略，前面有redisson的博文，我介绍过。 2.2 配置socketio的C","tags":["webSocket","Java"],"title":"Netty Socketio使用","uri":"https://cens7.github.io/2020/03/netty-socketio%E4%BD%BF%E7%94%A8/","year":"2020"},{"content":"背景 团队推行单元测试，需要对主要逻辑serice层做单元测试，但是有些service会有外部接口调用或上游接口调用，而因为环境问题，这部分接口又无法掉通，为了解决这个问题，我接入了Mockito。\n使用 1. 添加依赖 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.mockito\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mockito-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.23.4\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt;  2. 具体使用  @InjectMocks修饰需要测试的类 @Mock修饰需要mock掉的类 初始化mock注解 声明调用特定方法时，传入指定参数，返回指定指  when(xxx.yyy(zzz)).thenReturn(aaa); // 当调用xxx.yyy()方法且入参是zzz时，返回aaa；如果入参不是zzz，则返回null。 when(xxx.yyy()).thenAnswer(t -\u0026gt; {});// 当调用xxx.yyy()方法时，没有返回值，执行一个自定义的函数体。   如果被mock的类在需要测试的类中是一个私有的字段，则需要反射修改私有字段的值，将其替换成mock代理类 ReflectionTestUtils.setField(testObject, \u0026ldquo;field\u0026rdquo;, mockObject); test原本需要测试的方法  例：\nservice调用链：\n@Service public class MerchantDataService { @Reference private IMerchantUserService merchantUserService; public Object save(Object obj) { xxxxxx; ResponseEntity = merchantUserService.insert(xxxx); xxxxxx; return xxx; } }  单元测试使用：\n@SpringBootTest(classes = ApplicationStartup.class) @ActiveProfiles(\u0026quot;test\u0026quot;) public class MerchantDataServiceTest extends AbstractTransactionalTestNGSpringContextTests { @InjectMocks @Autowired private IMerchantDataService merchantDataService; @Mock private IMerchantUserService merchantUserService; @BeforeMethod(alwaysRun = true) public void initMock() { // 初始化mock注解 MockitoAnnotations.initMocks(this); ResponseEntity resp = new ResponseEntity().setStatus(Status.SUCCESS); // 当执行merchantUserService.insert方法时，返回申明的对象 when(merchantUserService.insert(new xxxx())).thenReturn(resp); } @Test public void testSave() { Object obj = new Object(); Object resultObj = merchantDataService.save(obj); Assert.assertTrue(respOthers.success()); } }  以上\n","id":2,"section":"posts","summary":"背景 团队推行单元测试，需要对主要逻辑serice层做单元测试，但是有些service会有外部接口调用或上游接口调用，而因为环境问题，这部分接","tags":["Java","测试"],"title":"单元测试Mockito使用心得","uri":"https://cens7.github.io/2020/02/%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95mockito%E4%BD%BF%E7%94%A8%E5%BF%83%E5%BE%97/","year":"2020"},{"content":"背景  听说kotlin跟Java生态无缝集成，尝试一下用kotlin写springBoot应用。\n 启动springboot:\n@SpringBootApplication @EnableScheduling open class NotifyApplication fun main(args: Array\u0026lt;String\u0026gt;) { val app = SpringApplication.run(NotifyApplication::class.java, *args) }  遇到的坑 1. spring无法托管kotlin bean 原因：spring托管bean使用的是aop代理，在默认情况下，使用jdk动态代理与字节码代理组合的模式；而kotlin的class默认是final class\n解决：在kotlin类上加open关键字，在kotlin fun前加open关键字。或者添加kotlin maven依赖，将其标注为allopen。 maven依赖：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.jetbrains.kotlin\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;kotlin-maven-allopen\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${kotlin.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;  2.lombok @Slf4j 注解在kotlin类上失效 原因：lombok.extern.slf4j.Slf4j 注解在kotlin的class上无法使用\n解决：在class中声明 private val logger = LoggerFactory.getLogger(javaClass) 替换原有的@Slf4j方式\n3. spring @Value(${xxx}) 失效 原因：在kotlin中，${}会被编译器特殊解析\n解决：加上转义标识 @Value(\u0026quot;${some.property}\u0026quot;)\n总结：目前只发现了以上几个问题，其他跟java一样使用springboot；另外就是kotlin自己的语法糖了。 ","id":3,"section":"posts","summary":"背景 听说kotlin跟Java生态无缝集成，尝试一下用kotlin写springBoot应用。 启动springboot: @SpringBootApplication @EnableScheduling open class NotifyApplication fun main(args: Array\u0026lt;String\u0026gt;) { val","tags":["Java","Kotlin"],"title":"使用Kotlin写SpringBoot的坑","uri":"https://cens7.github.io/2020/01/%E4%BD%BF%E7%94%A8kotlin%E5%86%99springboot%E7%9A%84%E5%9D%91/","year":"2020"},{"content":"常用命令    命令 描述     docker login 登陆   docker logout 登出   docker search [xxx] 搜索镜像   docker pull [xxx] 拉取指定名字的镜像   docker rm [container_id] 根据容器id删除   docker rmi [image_id] 根据镜像id删除   docker ps 查看所有正在运行的容器   docker container ps 查看所有正在运行的容器   docker container ps -a 查看所有容器   docker images 查看所有镜像   docker image ls 查看所有镜像   docker image ls -f dangling=true 查看虚悬镜像(官方发了新版)   dcker system df 查看doker镜像磁盘占用率   docker container rm [container_id] 根据容器id删除容器   docker image rm [image_id] 根据镜像id删除镜像   docker stop [container_id / container_name] 停止指定id的容器   docker start [container_id / container_name] 运行指定id的容器   docker volume create xxx 创建一个数据卷   docker volume ls 查看所有的数据卷   docker volume inspect xxx 查看指定的数据卷   docker volume rm xxx 删除指定的数据卷   docker volume prune 清理无效的数据卷   docker run xxx 运行指定镜像   docker exec -it xxx /bin/bash 进入指定容器   docker network ls 查看容器所有的网络   docker network prune 清理无效的网络   docker network 查看docker网络   docker logs [container_id] 查看指定容器id的日志   docker logs -f 查看指定容器的日志条数   docker port [container_id / container_name] 查询指定容器的端口映射    ","id":4,"section":"posts","summary":"常用命令 命令 描述 docker login 登陆 docker logout 登出 docker search [xxx] 搜索镜像 docker pull [xxx] 拉取指定名字的镜像 docker rm [container_id] 根据容器id删除 docker rmi [image_id] 根据镜像id删除 docker ps 查看所有正在运行的容器","tags":["docker"],"title":"docker使用","uri":"https://cens7.github.io/2019/12/docker%E4%BD%BF%E7%94%A8/","year":"2019"},{"content":"问题 同样的dubbo应用，同事启动只要10秒不到，我启动要2分钟，遂不服。万能的stackoverflow告诉我，我需要设置hosts。\n配置对应的hosts :(1) 127.0.0.1 localhost huanghuandeMacBook-Pro.local ::1 localhost huanghuandeMacBook-Pro.local  配置完成host发现启动从2分钟优化到了6秒！但是会有错误日志！作为强迫症的我岂能忍？！错误日志内容：开始调试：\n1. 先`telent 127.0.0.1 20880`本地dubbo, ok是好的； 2. ll 看一下本地的dubbo provider接口列表； 3. 选中一个，invoke xxx.xx.xx.xxxProvider.test()，ok也是好的。  以上说明我的dubbo接口成功。\n 1. 进入本地nacos看一下dubbo是否注册上去，ok是好的。  捋一捋，dubbo接口是好的，dubbo注册成功，但是为什么启动会报错。\n把改过的hosts改回去：(2)\n 127.0.0.1 localhost ::1 localhost  改回hosts,启动虽然慢了点，但是不报错。\n使用debug大法：\n 将hosts改成 (1) 从上面错误日志那行源码点进去打断点，发现dubbo绑定的地址是127.0.0.1。 将hosts改成 (2) 再启动，dubbo绑定的地址改成了我的内网ip192.168.5.143。很明显因为我配置了主机名，造成dubbo绑定的ip从内网ip192.168.5.143变成了主机ip127.0.0.1；所以这是为什么呢。其实官方已经在这里给了解释。  按照官方给的解释:\n Dubbo选取本地地址的逻辑大致分成了两步； 先去 /etc/hosts 文件中找 hostname 对应的 IP 地址，找到则返回；找不到则转到去 轮询网卡，寻找合适的 IP 地址，找到则返回；找不到返回 null，如果返回 null，则注册 127.0.0.1 这个本地回环地址\n 所以我的问题就是没有找到合适的ip地址而去注册了127.0.0.1这个本地地址。\n于是将我的hosts改成：192.168.5.143 localhost huanghuandeMacBook-Pro.local ::1 localhost huanghuandeMacBook-Pro.local  或者：在启动应用的时候加上启动参数： -DDUBBO_IP_TO_BIND=192.168.5.143  问题解决。\n","id":5,"section":"posts","summary":"问题 同样的dubbo应用，同事启动只要10秒不到，我启动要2分钟，遂不服。万能的stackoverflow告诉我，我需要设置hosts。 配置","tags":["Java","Dubbo","架构","问题"],"title":"Dubbo启动太慢","uri":"https://cens7.github.io/2019/12/dubbo%E5%90%AF%E5%8A%A8%E5%A4%AA%E6%85%A2/","year":"2019"},{"content":"一、背景 介绍：XSS(Cross Site Scripting)指的是用户注入恶意的代码，浏览器和服务器没有对用户的输入进行过滤，导致用户注入的脚本嵌入到了页面中。由于浏览器无法识别这些恶意代码正常解析执行，攻击者的恶意操作被成功执行。\n预防XSS攻击不仅是前端开发人员要做的事情，也是是后端开发人员要做的事情。本篇章节是针对后端开发人员怎么预防XSS攻击。\n常见的XSS攻击分为三种：\n 反射型： 通过在请求地址上加上恶心的HTML代码。 dom型： 通过一些api向网站注入一些恶心的HTML代码。 持久型： 攻击者通过把代码提交到后台数据库中;当用户下次打开的时候就会从后台接收这些恶意的代码。  防范：\n 反射型： 前端通过转义来进行防范以及过滤 dom型：前端通过转义来进行防范以及过滤 持久型：服务端通过转义存储进行防范  对于反射型与dom型的XSS攻击，需要前端做转义。本篇博客主要讲解后端的转义处理。\n二、目的  针对输入包含dom敏感的数据进行过滤 针对输入包含sql相关的敏感信息进行过滤  三、实现方式 使用Filter过滤器使用Filter，将所有的敏感信息替换成空字符串  public class XSSPreventionFilter implements Filter { @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException { XSSRequestWrapper wrapper = new XSSRequestWrapper((HttpServletRequest) request); chain.doFilter(wrapper, response); } class XSSRequestWrapper extends HttpServletRequestWrapper { private Map\u0026lt;String, String[]\u0026gt; sanitizedQueryString; XSSRequestWrapper(HttpServletRequest request) { super(request); } @Override public String getParameter(String name) { String parameter = null; String[] vals = getParameterMap().get(name); if (vals != null \u0026amp;\u0026amp; vals.length \u0026gt; 0) { parameter = vals[0]; } return parameter; } @Override public String[] getParameterValues(String name) { return getParameterMap().get(name); } @Override public Enumeration\u0026lt;String\u0026gt; getParameterNames() { return Collections.enumeration(getParameterMap().keySet()); } @Override public Map\u0026lt;String, String[]\u0026gt; getParameterMap() { if (sanitizedQueryString == null) { Map\u0026lt;String, String[]\u0026gt; res = new HashMap\u0026lt;\u0026gt;(); Map\u0026lt;String, String[]\u0026gt; originalQueryString = super.getParameterMap(); if (originalQueryString != null) { for (String key : originalQueryString.keySet()) { String[] rawVals = originalQueryString.get(key); String[] snzVals = new String[rawVals.length]; for (int i = 0; i \u0026lt; rawVals.length; i++) { snzVals[i] = stripXSS(rawVals[i]); } res.put(stripXSS(key), snzVals); } } sanitizedQueryString = res; } return sanitizedQueryString; } /** * 从字符串中删除所有潜在的恶意字符 * * @param value the raw string * @return the sanitized string */ private String stripXSS(String value) { String cleanValue = null; if (value != null) { cleanValue = Normalizer.normalize(value, Normalizer.Form.NFD); // 删除空字符 cleanValue = cleanValue.replaceAll(\u0026quot;\\0\u0026quot;, \u0026quot;\u0026quot;); // 删除\u0026lt;script\u0026gt;\u0026lt;/script\u0026gt;标签 Pattern scriptPattern = Pattern.compile(\u0026quot;\u0026lt;script\u0026gt;(.*?)\u0026lt;/script\u0026gt;\u0026quot;, Pattern.CASE_INSENSITIVE); cleanValue = scriptPattern.matcher(cleanValue).replaceAll(\u0026quot;\u0026quot;); // 删除src='...' scriptPattern = Pattern.compile(\u0026quot;src[\\r\\n]*=[\\r\\n]*'(.*?)'\u0026quot;, Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL); cleanValue = scriptPattern.matcher(cleanValue).replaceAll(\u0026quot;\u0026quot;); // 删除\u0026lt;/script\u0026gt;标签 scriptPattern = Pattern.compile(\u0026quot;\u0026lt;/script\u0026gt;\u0026quot;, Pattern.CASE_INSENSITIVE); cleanValue = scriptPattern.matcher(cleanValue).replaceAll(\u0026quot;\u0026quot;); // 删除\u0026lt;script ...\u0026gt;标签 scriptPattern = Pattern.compile(\u0026quot;\u0026lt;script(.*?)\u0026gt;\u0026quot;, Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL); cleanValue = scriptPattern.matcher(cleanValue).replaceAll(\u0026quot;\u0026quot;); // 删除eval(...)表达式 scriptPattern = Pattern.compile(\u0026quot;eval\\\\((.*?)\\\\)\u0026quot;, Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL); cleanValue = scriptPattern.matcher(cleanValue).replaceAll(\u0026quot;\u0026quot;); // 删除expression(...)表达式 scriptPattern = Pattern.compile(\u0026quot;expression\\\\((.*?)\\\\)\u0026quot;, Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL); cleanValue = scriptPattern.matcher(cleanValue).replaceAll(\u0026quot;\u0026quot;); // 删除javascript:...表达式 scriptPattern = Pattern.compile(\u0026quot;javascript:\u0026quot;, Pattern.CASE_INSENSITIVE); cleanValue = scriptPattern.matcher(cleanValue).replaceAll(\u0026quot;\u0026quot;); // 删除vbscript:...表达式 scriptPattern = Pattern.compile(\u0026quot;vbscript:\u0026quot;, Pattern.CASE_INSENSITIVE); cleanValue = scriptPattern.matcher(cleanValue).replaceAll(\u0026quot;\u0026quot;); // 删除onload= 表达式 scriptPattern = Pattern.compile(\u0026quot;onload(.*?)=\u0026quot;, Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL); cleanValue = scriptPattern.matcher(cleanValue).replaceAll(\u0026quot;\u0026quot;); // 删除 sql ' 和 ; 字符串 scriptPattern = Pattern.compile(\u0026quot;[';]\u0026quot;, Pattern.CASE_INSENSITIVE); cleanValue = scriptPattern.matcher(cleanValue).replaceAll(\u0026quot;\u0026quot;); // 删除 sql -- 字符 scriptPattern = Pattern.compile(\u0026quot;--\u0026quot;, Pattern.CASE_INSENSITIVE); cleanValue = scriptPattern.matcher(cleanValue).replaceAll(\u0026quot;\u0026quot;); } return cleanValue; } } }  配置Filter过滤器\n配置xss防注入filter bean  @Configuration public class FilterConfig { @Bean public FilterRegistrationBean filterRegistrationBean() { FilterRegistrationBean frb = new FilterRegistrationBean(); frb.setFilter(new XSSPreventionFilter()); frb.setOrder(1); frb.addUrlPatterns(\u0026quot;/*\u0026quot;); return frb; } }  以上完成，搞定。\n","id":6,"section":"posts","summary":"一、背景 介绍：XSS(Cross Site Scripting)指的是用户注入恶意的代码，浏览器和服务器没有对用户的输入进行过滤，导致用户注入的脚本嵌","tags":["Java","安全","xss"],"title":"防xss攻击","uri":"https://cens7.github.io/2019/11/%E9%98%B2xss%E6%94%BB%E5%87%BB/","year":"2019"},{"content":"使用redisson 1.pom依赖  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.redisson\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;redisson\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;   2.配置对应redisson @Configuration public class RedissonConfig { @Autowired(required = false) RedissonProperties redissonProperties; @Bean(destroyMethod = \u0026quot;shutdown\u0026quot;) @ConditionalOnMissingBean(RedissonClient.class) public RedissonClient redissonClient() { if (Objects.nonNull(redissonProperties)) { Config config = new Config(); String[] nodes = redissonProperties.getSentinelNodes().split(\u0026quot;,\u0026quot;); SentinelServersConfig sentinelServersConfig = config.useSentinelServers() .setMasterName(redissonProperties.getMasterName()) .setDatabase(redissonProperties.getDatabase()) .setConnectTimeout(redissonProperties.getConnectTimeout()) .setPassword(redissonProperties.getPassword()); for (String node : nodes) { sentinelServersConfig = sentinelServersConfig.addSentinelAddress(\u0026quot;redis://\u0026quot; + node); } return Redisson.create(config); } else { return null; } } }  3.使用 这里是官方文档\n1) 使用普通锁(可重入锁) 注意：可重入锁lock()几次，就要对应的unlock()几次\npublic static void main(String[] args) { RedissonClient redisson = new RedissonClient; RLock lock = redisson.getLock(\u0026quot;lock\u0026quot;); lock.lock(2, TimeUnit.SECONDS); Thread t = new Thread(() -\u0026gt; { RLock lock1 = redisson.getLock(\u0026quot;lock\u0026quot;); lock1.lock(); lock1.unlock(); }); t.start(); t.join(); lock.unlock(); }  2) 使用公平锁 公平锁秉持先到先得原则，先请求获取锁的线程先获取到锁，后来的线程等待。\n@Autowired private RedissonClient redisson; public void demo() { RLock lock = redisson.getLock(\u0026quot;lock\u0026quot;); lock.lock(2, TimeUnit.SECONDS); Thread t = new Thread(() -\u0026gt; { RLock lock1 = redisson.getLock(\u0026quot;lock\u0026quot;); lock1.lock(); lock1.unlock(); }); t.start(); t.join(); lock.unlock(); }  3) 使用读写锁 @Autowired private RedissonClient redisson; public void demo() throws InterruptedException { final RReadWriteLock lock = redisson.getReadWriteLock(\u0026quot;lock\u0026quot;); lock.writeLock().tryLock(); Thread t = new Thread() { public void run() { RLock r = lock.readLock(); r.lock(2, TimeUnit.SECONDS); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } r.unlock(); }; }; t.start(); t.join(); lock.writeLock().unlock(); t.join(); }  4) 使用红锁 使用redlock需要多个redissonClient，多个redissonClient需要多个互相独立的哨兵，我们的项目里目前只有一个哨兵，所以暂不推荐使用红锁\n上面是4种比较常用的分布式锁机制，我们针对不同业务作出不同选型。\n redisson将各种锁的概念与java的各种锁完美的结合在一起，封装做的非常巧妙，甚至对于CountDownLatch、Semaphore、Atomic等等也有很多精妙绝伦的封装，感兴趣的同学可以研究一下官方文档。\n 注意：1. 不管使用哪一种锁，都需要设置锁的过期时间。 2. 使用lock()、tryLock()时，一定要放在try{}catch(){}中，且unlock一定要放在finally{}里 3. 所有需要使用分布式锁场景的锁名，都要使用枚举、常量统一管理  redisson锁原理 1) tryLock()表示尝试加锁，加锁成功返回true，加锁失败返回false。使用tryLock()加锁，线程没有获取到锁不会阻塞。 使用tryLock()加锁流程： 2) lock() 加锁，此锁已被持有则等待，没有被持有则获取这把锁。使用lock()加锁，线程没有获取到锁会一直阻塞直到获取到锁。 使用lock()加锁流程： 3) 使用可重入锁、公平锁、读写锁时，执行的lua脚本各不相同。    类型 加锁lua 解锁lua     可重入锁 红锁     公平锁     读锁     写锁      4）tryLock()与lock()的使用场景  场景一： 库存抢占。有效库存只有100，多个应用来抢占这100个库存总数。这时使用：lock() 场景二： 退款申请。网络卡顿或其他原因同时段提交多次退款申请，实际只生成一条退款单。这时使用：tryLock()  5）tryLock()与lcok()使用的注意事项  tryLock() 尝试获取锁,不等待，返回获取结果。 tryLock(long waitTime, TimeUnit timeUnit) 尝试获取锁，并等待waitTime个时间单位，之后返回获取结果。 tryLock(long waitTime, long leaseTime, TimeUnit timeUnit) 尝试获取锁，并等待waitTIme个时间单位，并将此锁持有leaseTime个时间单位，之后返回获取结果。 lock() 获取锁，线程阻塞，直到获取到锁为止，锁不过期，直到解锁或者被内部机制释放。 lock(long leaseTime, TimeUnit timeUnit) 获取锁，直到获取到锁为止，持有锁leaseTime个时间单位，之后自动释放锁，也可以提前手动释放。  6）公平锁、可重入锁、读写锁、红锁的使用场景   场景一： 门票只有100张。先到先得。这时使用公平锁  场景二： 1. 门票只有100张，需要抢票。2. 需要把下一张门票修改成vip票。 (可重入锁是在一个线程中多次获取同一把锁。一个线程在执行一个带锁的方法时，该方法中又调用了另一个需要相同锁的方法，则该线程可以直接执行调用的方法，而无需重新获得锁)  场景三： 所有人都能看到库存信息，但同时只有一个人来修改库存。所有的人都能看到库存信息，使用读锁。同时只有一个人来修改库存，使用写锁。多个读锁不互斥，读锁与写锁互斥  场景四： 当需要超级高可用锁的场景时，使用红锁。\n综上所述，使用tryLock还是lock，使用公平锁还是读写锁都是看具体的业务和场景而言。\n  ","id":7,"section":"posts","summary":"使用redisson 1.pom依赖 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.redisson\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;redisson\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 2.配置对应redisson @Configuration public class RedissonConfig { @Autowired(required = false) RedissonProperties redissonProperties; @Bean(destroyMethod = \u0026quot;shutdown\u0026quot;) @ConditionalOnMissingBean(RedissonClient.class) public RedissonClient redissonClient() { if (Objects.nonNull(redissonProperties)) { Config config = new Config(); String[] nodes = redissonProperties.getSentinelNodes().split(\u0026quot;,\u0026quot;); SentinelServersConfig sentinelServersConfig = config.useSentinelServers()","tags":["Java","redis"],"title":"使用redisson做分布式锁","uri":"https://cens7.github.io/2019/11/%E4%BD%BF%E7%94%A8redisson%E5%81%9A%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/","year":"2019"},{"content":" 从数据库工具（比如：navicat）中导出表结构sql。 将sql导入到powerDesigner里。  File → Reverse Engineer → Database选中导出的表结构sql点确定，生成pdm   将comment的值写到name上Tools → Execute Commonds → Edit/Run Script    写入代码点run，然后close弹窗：  Option Explicit ValidationMode = True InteractiveMode = im_Batch Dim mdl 'the current model 'get the current active model Set mdl = ActiveModel If (mdl Is Nothing) Then MsgBox \u0026quot;There is no current Model\u0026quot; ElseIf Not mdl.IsKindOf(PdPDM.cls_Model) Then MsgBox \u0026quot;The current model is not an Physical Data model.\u0026quot; Else ProcessFolder mdl End If 'This routine copy name into code for each table, each column and each view 'of the current folder Private sub ProcessFolder(folder) Dim Tab 'running table for each Tab in folder.tables if not tab.isShortcut then if len(tab.comment) \u0026lt;\u0026gt; 0 then tab.name = tab.comment end if On Error Resume Next Dim col 'running column for each col in tab.columns if len(col.comment) \u0026lt;\u0026gt;0 then col.name =col.comment end if On Error Resume Next next end if next end sub   把code驼峰转为下划线  Option Explicit ValidationMode = True InteractiveMode = im_Batch Dim mdl 'the current model Set mdl = ActiveModel If (mdl Is Nothing) Then MsgBox \u0026quot;There is no current Model\u0026quot; ElseIf Not mdl.IsKindOf(PdPDM.cls_Model) Then MsgBox \u0026quot;The current model is not an Physical Data model.\u0026quot; Else ProcessFolder mdl End If Private sub ProcessFolder(folder) Dim Tab for each Tab in folder.tables Dim col for each col in tab.columns Dim ch Dim exaStr exaStr = \u0026quot;\u0026quot; Dim intCounter Dim intLen Dim arrChars intLen = Len(col.code)-1 redim arrChars(intLen) For intCounter = 0 to intLen arrChars(intCounter) = Mid(col.code, intCounter + 1,1) Next for each ch in arrChars Dim tmpCh tmpCh = LCase(ch) If StrComp(ch, tmpCh)=0 Then exaStr = exaStr + ch Else exaStr = exaStr + \u0026quot;_\u0026quot; + tmpCh End If next col.code = exaStr next next end sub  搞定\n","id":8,"section":"posts","summary":"从数据库工具（比如：navicat）中导出表结构sql。 将sql导入到powerDesigner里。 File → Reverse Engineer → Database选中导出的表结","tags":["工具"],"title":"PowerDesigner行列转换脚本","uri":"https://cens7.github.io/2019/08/powerdesigner%E8%A1%8C%E5%88%97%E8%BD%AC%E6%8D%A2%E8%84%9A%E6%9C%AC/","year":"2019"},{"content":"背景 随着业务发展，订单线上数据已到达每日200万+，需要提前对订单做分库分表。结合市面上解决方案，决定采用sharding。sharding支持只分库，只分表，分库并分表。针对订单业务，我采用的是分库并分表。\n使用  sharding官网有很清晰的教程，本文是对使用过程中问题的一个记录。\n 我是用的是javaBean的配置形式，也支持yaml与properties，因人而异。\n1. 配置分库算法 public class OrderDatabaseAlgorithm implements PreciseShardingAlgorithm\u0026lt;String\u0026gt; { @Override public String doSharding(Collection\u0026lt;String\u0026gt; databaseNames, PreciseShardingValue\u0026lt;String\u0026gt; shardingValue) { String value = shardingValue.getValue(); // 将数据库分为order_0 ~ order_15 15个数据库 String key = String.valueOf(value.hashCode() \u0026amp; 15); String dsName = \u0026quot;\u0026quot;; for (String each : databaseNames) { if (each.endsWith(key)) { dsName = each; break; } } return dsName; } }  2. 配置分表算法 public class OrderTableAlgorithm implements PreciseShardingAlgorithm\u0026lt;String\u0026gt; { @Override public String doSharding(Collection\u0026lt;String\u0026gt; availableTargetNames, PreciseShardingValue\u0026lt;String\u0026gt; preciseShardingValue) { String value = preciseShardingValue.getValue(); // 将order表分为order_0 ~ order_127 128张表 String key = String.valueOf(value.hashCode() \u0026amp; 127); return preciseShardingValue.getLogicTableName() + \u0026quot;_\u0026quot; + key; } }  我将订单根据分片键分为128张表，16个库。 128*16=2048张表\n3. 数据库配置类 @Data public class ShardingSliceProperties { private String driverClassName; private String jdbcUrl; private String username; private String password; // 分片数据库 private String sliceDatabase; // 分片表 private String sliceTable; // 数据库分片键 private String sliceDatabaseKey; // 表分片键 private String sliceTableKey; }  4. 配置分库分表规则，并注入数据源 @Configuration public class ShardingConfig { @Bean public DataSource getShardingDataSource(ShardingSliceProperties shardingSliceProperties) throws SQLException { ShardingRuleConfiguration shardingRuleConfig = new ShardingRuleConfiguration(); TableRuleConfiguration tableRuleConfiguration = new TableRuleConfiguration(shardingSliceProperties.getSliceTable(), shardingSliceProperties.getSliceDatabase() + \u0026quot;_${0..15}.\u0026quot; + shardingSliceProperties.getSliceTable() + \u0026quot;_${0..127}\u0026quot;); // 设置表规则 shardingRuleConfig.getTableRuleConfigs().add(tableRuleConfiguration); // 设置分库规则 shardingRuleConfig.setDefaultDatabaseShardingStrategyConfig(new StandardShardingStrategyConfiguration( shardingSliceProperties.getSliceDatabaseKey(), new OrderDatabaseAlgorithm())); // 设置分表规则 shardingRuleConfig.setDefaultTableShardingStrategyConfig(new StandardShardingStrategyConfiguration( shardingSliceProperties.getSliceTableKey(), new OrderTableAlgorithm())); // 配置数据源 Map\u0026lt;String, DataSource\u0026gt; dataSourceMap = new HashMap\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; 16; i++) { HikariConfig hikariConfig = new HikariConfig(); hikariConfig.setDriverClassName(shardingSliceProperties.getDriverClassName()); hikariConfig.setJdbcUrl(shardingSliceProperties.getJdbcUrl() + \u0026quot;/\u0026quot; + shardingSliceProperties.getSliceDatabase() + \u0026quot;_\u0026quot; + i); hikariConfig.setUsername(shardingSliceProperties.getUsername()); hikariConfig.setPassword(shardingSliceProperties.getPassword()); hikariConfig.setMaximumPoolSize(25); hikariConfig.setMinimumIdle(5); HikariDataSource hikariDataSource = new HikariDataSource(hikariConfig); dataSourceMap.put(shardingSliceProperties.getSliceDatabase() + \u0026quot;_\u0026quot; + i, hikariDataSource); } Properties props = new Properties(); // 设置显示sql props.put(ShardingPropertiesConstant.SQL_SHOW.getKey(), String.valueOf(Boolean.TRUE)); return ShardingDataSourceFactory.createDataSource(dataSourceMap, shardingRuleConfig, props); } }  启动一下：\n2019-07-31 20:23:43.153 INFO o.a.c.core.StandardService log:173 Starting service [Tomcat] 2019-07-31 20:23:43.153 INFO o.a.catalina.core.StandardEngine log:173 Starting Servlet engine: [Apache Tomcat/9.0.21] 2019-07-31 20:23:43.269 INFO o.a.c.c.C.[.[localhost].[/] log:173 Initializing Spring embedded WebApplicationContext 2019-07-31 20:23:43.269 INFO o.s.web.context.ContextLoader prepareWebApplicationContext:283 Root WebApplicationContext: initialization completed in 2531 ms 2019-07-31 20:23:43.710 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:80 HikariPool-1 - Starting... 2019-07-31 20:23:43.867 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:82 HikariPool-1 - Start completed. 2019-07-31 20:23:43.868 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:80 HikariPool-2 - Starting... 2019-07-31 20:23:43.916 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:82 HikariPool-2 - Start completed. 2019-07-31 20:23:43.917 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:80 HikariPool-3 - Starting... 2019-07-31 20:23:43.939 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:82 HikariPool-3 - Start completed. 2019-07-31 20:23:43.939 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:80 HikariPool-4 - Starting... 2019-07-31 20:23:44.166 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:82 HikariPool-4 - Start completed. 2019-07-31 20:23:44.166 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:80 HikariPool-5 - Starting... 2019-07-31 20:23:44.192 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:82 HikariPool-5 - Start completed. 2019-07-31 20:23:44.193 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:80 HikariPool-6 - Starting... 2019-07-31 20:23:44.216 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:82 HikariPool-6 - Start completed. 2019-07-31 20:23:44.217 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:80 HikariPool-7 - Starting... 2019-07-31 20:23:44.239 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:82 HikariPool-7 - Start completed. 2019-07-31 20:23:44.239 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:80 HikariPool-8 - Starting... 2019-07-31 20:23:44.262 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:82 HikariPool-8 - Start completed. 2019-07-31 20:23:44.262 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:80 HikariPool-9 - Starting... 2019-07-31 20:23:44.284 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:82 HikariPool-9 - Start completed. 2019-07-31 20:23:44.285 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:80 HikariPool-10 - Starting... 2019-07-31 20:23:44.304 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:82 HikariPool-10 - Start completed. 2019-07-31 20:23:44.305 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:80 HikariPool-11 - Starting... 2019-07-31 20:23:44.330 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:82 HikariPool-11 - Start completed. 2019-07-31 20:23:44.330 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:80 HikariPool-12 - Starting... 2019-07-31 20:23:44.349 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:82 HikariPool-12 - Start completed. 2019-07-31 20:23:44.350 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:80 HikariPool-13 - Starting... 2019-07-31 20:23:44.377 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:82 HikariPool-13 - Start completed. 2019-07-31 20:23:44.377 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:80 HikariPool-14 - Starting... 2019-07-31 20:23:44.400 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:82 HikariPool-14 - Start completed. 2019-07-31 20:23:44.401 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:80 HikariPool-15 - Starting... 2019-07-31 20:23:44.424 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:82 HikariPool-15 - Start completed. 2019-07-31 20:23:44.425 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:80 HikariPool-16 - Starting... 2019-07-31 20:23:44.448 INFO c.zaxxer.hikari.HikariDataSource \u0026lt;init\u0026gt;:82 HikariPool-16 - Start completed. 2019-07-31 20:23:44.792 INFO o.a.s.c.c.l.ConfigurationLogger log:134 ShardingRuleConfiguration defaultDatabaseStrategy: standard: preciseAlgorithmClassName: com.aduer.pay.order.config.OrderDatabaseAlgorithm shardingColumn: merchant_no defaultTableStrategy: standard: preciseAlgorithmClassName: com.aduer.pay.order.config.OrderTableAlgorithm shardingColumn: merchant_no tables: order: actualDataNodes: pay-order_${0..15}.order_${0..127} logicTable: order 2019-07-31 20:23:44.793 INFO o.a.s.c.c.l.ConfigurationLogger log:134 Properties sql.show: 'true'  看日志，正确加载了数据源与数据表，测试一下，正常并通过。搞定。\n以上。\n","id":9,"section":"posts","summary":"背景 随着业务发展，订单线上数据已到达每日200万+，需要提前对订单做分库分表。结合市面上解决方案，决定采用sharding。sharding","tags":["Java","数据库","分库分表"],"title":"ShardingSphere使用心得","uri":"https://cens7.github.io/2019/07/shardingsphere%E4%BD%BF%E7%94%A8%E5%BF%83%E5%BE%97/","year":"2019"},{"content":"IO,NIO,AIO 学习与总结 Java 中的 BIO、NIO和 AIO 理解为是 Java 语言对操作系统的各种 IO 模型的封装。程序员在使用这些 API 的时候，不需要关心操作系统层面的知识，也不需要根据不同操作系统编写不同的代码。只需要使用Java的API就可以了。\n在讲 BIO,NIO,AIO 之前先来回顾一下这样几个概念：同步与异步，阻塞与非阻塞。\n关于同步和异步的概念解读困扰着很多程序员，大部分的解读都会带有自己的一点偏见。参考了 Stackoverflow相关问题后对原有答案进行了进一步完善：\n When you execute something synchronously, you wait for it to finish before moving on to another task. When you execute something asynchronously, you can move on to another task before it finishes.\n  当你同步执行某项任务时，你需要等待其完成才能继续执行其他任务。当你异步执行某些操作时，你可以在完成另一个任务之前继续进行。\n  同步：两个同步任务相互依赖，并且一个任务必须以依赖于另一任务的某种方式执行。 比如在A-\u0026gt;B事件模型中，你需要先完成 A 才能执行B。 再换句话说，同步调用种被调用者未处理完请求之前，调用不返回，调用者会一直等待结果的返回。 异步： 两个异步的任务完全独立的，一方的执行不需要等待另外一方的执行。再换句话说，异步调用种一调用就返回结果不需要等待结果返回，当结果返回的时候通过回调函数或者其他方式拿着结果再做相关事情。  阻塞和非阻塞  阻塞： 阻塞就是发起一个请求，调用者一直等待请求结果返回，也就是当前线程会被挂起，无法从事其他任务，只有当条件就绪才能继续。 非阻塞： 非阻塞就是发起一个请求，调用者不用一直等着结果返回，可以先去干其他事情。  如何区分 “同步/异步 ”和 “阻塞/非阻塞” 呢？同步/异步是从行为角度描述事物的，而阻塞和非阻塞描述的当前事物的状态（等待调用结果时的状态）。\n1. BIO (Blocking I/O) 同步阻塞I/O模式，数据的读取写入必须阻塞在一个线程内等待其完成。\n1.1 传统 BIO BIO通信（一请求一应答）模型图如下：采用BIO 通信模型的服务端，通常由一个独立的 Acceptor 线程负责监听客户端的连接。我们一般通过在while(true) 循环中服务端会调用 accept() 方法等待接收客户端的连接的方式监听请求，请求一旦接收到一个连接请求，就可以建立通信套接字在这个通信套接字上进行读写操作，此时不能再接收其他客户端连接请求，只能等待同当前连接的客户端的操作执行完成， 不过可以通过多线程来支持多个客户端的连接，如上图所示。\n如果要让BIO 通信模型能够同时处理多个客户端请求，就必须使用多线程（主要原因是socket.accept()、socket.read()、socket.write() 涉及的三个主要函数都是同步阻塞的），也就是说它在接收到客户端连接请求之后为每个客户端创建一个新的线程进行链路处理，处理完成之后，通过输出流返回应答给客户端，线程销毁。这就是典型的一请求一应答通信模型 。我们可以设想一下如果这个连接不做任何事情的话就会造成不必要的线程开销，不过可以通过线程池机制 改善，线程池还可以让线程的创建和回收成本相对较低。使用FixedThreadPool 可以有效的控制了线程的最大数量，保证了系统有限的资源的控制，实现了N(客户端请求数量):M(处理客户端请求的线程数量)的伪异步I/O模型（N 可以远远大于 M），下面一节\u0026quot;伪异步 BIO\u0026quot;中会详细介绍到。\n我们再设想一下当客户端并发访问量增加后这种模型会出现什么问题？\n在 Java 虚拟机中，线程是宝贵的资源，线程的创建和销毁成本很高，除此之外，线程的切换成本也是很高的。尤其在 Linux 这样的操作系统中，线程本质上就是一个进程，创建和销毁线程都是重量级的系统函数。如果并发访问量增加会导致线程数急剧膨胀可能会导致线程堆栈溢出、创建新线程失败等问题，最终导致进程宕机或者僵死，不能对外提供服务。\n1.2 伪异步 IO 为了解决同步阻塞I/O面临的一个链路需要一个线程处理的问题，后来有人对它的线程模型进行了优化一一一后端通过一个线程池来处理多个客户端的请求接入，形成客户端个数M：线程池最大线程数N的比例关系，其中M可以远远大于N.通过线程池可以灵活地调配线程资源，设置线程的最大值，防止由于海量并发接入导致线程耗尽。\n伪异步IO模型图：采用线程池和任务队列可以实现一种叫做伪异步的 I/O 通信框架，它的模型图如上图所示。当有新的客户端接入时，将客户端的 Socket 封装成一个Task（该任务实现java.lang.Runnable接口）投递到后端的线程池中进行处理，JDK 的线程池维护一个消息队列和 N 个活跃线程，对消息队列中的任务进行处理。由于线程池可以设置消息队列的大小和最大线程数，因此，它的资源占用是可控的，无论多少个客户端并发访问，都不会导致资源的耗尽和宕机。\n伪异步I/O通信框架采用了线程池实现，因此避免了为每个请求都创建一个独立线程造成的线程资源耗尽问题。不过因为它的底层仍然是同步阻塞的BIO模型，因此无法从根本上解决问题。\n1.3 代码示例 下面代码中演示了BIO通信（一请求一应答）模型。我们会在客户端创建多个线程依次连接服务端并向其发送\u0026quot;当前时间+:hello world\u0026rdquo;，服务端会为每个客户端线程创建一个线程来处理。代码原地址如下：https://www.jianshu.com/p/a4e03835921a 客户端public class IOClient { public static void main(String[] args) { // TODO 创建多个线程，模拟多个客户端连接服务端 new Thread(() -\u0026gt; { try { Socket socket = new Socket(\u0026quot;127.0.0.1\u0026quot;, 3333); while (true) { try { socket.getOutputStream().write((new Date() + \u0026quot;: hello world\u0026quot;).getBytes()); Thread.sleep(2000); } catch (Exception e) { } } } catch (IOException e) { } }).start(); } }  服务端public class IOServer { public static void main(String[] args) throws IOException { // TODO 服务端处理客户端连接请求 ServerSocket serverSocket = new ServerSocket(3333); // 接收到客户端连接请求之后为每个客户端创建一个新的线程进行链路处理 new Thread(() -\u0026gt; { while (true) { try { // 阻塞方法获取新的连接 Socket socket = serverSocket.accept(); // 每一个新的连接都创建一个线程，负责读取数据 new Thread(() -\u0026gt; { try { int len; byte[] data = new byte[1024]; InputStream inputStream = socket.getInputStream(); // 按字节流方式读取数据 while ((len = inputStream.read(data)) != -1) { System.out.println(new String(data, 0, len)); } } catch (IOException e) { } }).start(); } catch (IOException e) { } } }).start(); } }  1.4 总结 在活动连接数不是特别高（小于单机1000）的情况下，这种模型是比较不错的，可以让每一个连接专注于自己的 I/O 并且编程模型简单，也不用过多考虑系统的过载、限流等问题。线程池本身就是一个天然的漏斗，可以缓冲一些系统处理不了的连接或请求。但是，当面对十万甚至百万级连接的时候，传统的 BIO 模型是无能为力的。因此，我们需要一种更高效的 I/O 处理模型来应对更高的并发量。\n2. NIO (New I/O) 2.1 NIO 简介 NIO是一种同步非阻塞的I/O模型，在Java 1.4 中引入了 NIO 框架，对应 java.nio 包，提供了 Channel , Selector，Buffer等抽象。\nNIO中的N可以理解为Non-blocking，不单纯是New。它支持面向缓冲的，基于通道的I/O操作方法。 NIO提供了与传统BIO模型中的 Socket 和 ServerSocket 相对应的 SocketChannel 和 ServerSocketChannel 两种不同的套接字通道实现,两种通道都支持阻塞和非阻塞两种模式。阻塞模式使用就像传统中的支持一样，比较简单，但是性能和可靠性都不好；非阻塞模式正好与之相反。对于低负载、低并发的应用程序，可以使用同步阻塞I/O来提升开发速率和更好的维护性；对于高负载、高并发的（网络）应用，应使用 NIO 的非阻塞模式来开发。\n2.2 NIO的特性/NIO与IO区别 如果是在面试中回答这个问题，我觉得首先肯定要从 NIO 流是非阻塞 IO 而 IO 流是阻塞 IO 说起。然后，可以从 NIO 的3个核心组件/特性为 NIO 带来的一些改进来分析。如果，你把这些都回答上了我觉得你对于 NIO 就有了更为深入一点的认识，面试官问到你这个问题，你也能很轻松的回答上来了。\n1)Non-blocking IO（非阻塞IO） IO流是阻塞的，NIO流是不阻塞的。Java NIO使我们可以进行非阻塞IO操作。比如说，单线程中从通道读取数据到buffer，同时可以继续做别的事情，当数据读取到buffer中后，线程再继续处理数据。写数据也是一样的。另外，非阻塞写也是如此。一个线程请求写入一些数据到某通道，但不需要等待它完全写入，这个线程同时可以去做别的事情。\nJava IO的各种流是阻塞的。这意味着，当一个线程调用 read() 或 write() 时，该线程被阻塞，直到有一些数据被读取，或数据完全写入。该线程在此期间不能再干任何事情了\n2)Buffer(缓冲区) IO 面向流(Stream oriented)，而 NIO 面向缓冲区(Buffer oriented)。Buffer是一个对象，它包含一些要写入或者要读出的数据。在NIO类库中加入Buffer对象，体现了新库与原I/O的一个重要区别。在面向流的I/O中·可以将数据直接写入或者将数据直接读到 Stream 对象中。虽然 Stream 中也有 Buffer 开头的扩展类，但只是流的包装类，还是从流读到缓冲区，而 NIO 却是直接读到 Buffer 中进行操作。\n在NIO厍中，所有数据都是用缓冲区处理的。在读取数据时，它是直接读到缓冲区中的; 在写入数据时，写入到缓冲区中。任何时候访问NIO中的数据，都是通过缓冲区进行操作。\n最常用的缓冲区是 ByteBuffer,一个 ByteBuffer 提供了一组功能用于操作 byte 数组。除了ByteBuffer,还有其他的一些缓冲区，事实上，每一种Java基本类型（除了Boolean类型）都对应有一种缓冲区。\n3)Channel (通道) NIO 通过Channel（通道） 进行读写。通道是双向的，可读也可写，而流的读写是单向的。无论读写，通道只能和Buffer交互。因为 Buffer，通道可以异步地读写。\n4)Selector (选择器) NIO有选择器，而IO没有。选择器用于使用单个线程处理多个通道。因此，它需要较少的线程来处理这些通道。线程之间的切换对于操作系统来说是昂贵的。 因此，为了提高系统效率选择器是有用的。2.3 NIO 读数据和写数据方式 通常来说NIO中的所有IO都是从 Channel（通道） 开始的。\n 从通道进行数据读取 ：创建一个缓冲区，然后请求通道读取数据。 从通道进行数据写入 ：创建一个缓冲区，填充数据，并要求通道写入数据。  数据读取和写入操作图示：2.4 NIO核心组件简单介绍 NIO 包含下面几个核心的组件：\n Channel(通道) Buffer(缓冲区) Selector(选择器)  整个NIO体系包含的类远远不止这三个，只能说这三个是NIO体系的“核心API”。\n2.5 代码示例 public class NIOServer { public static void main(String[] args) throws IOException { // 1. serverSelector负责轮询是否有新的连接，服务端监测到新的连接之后，不再创建一个新的线程， // 而是直接将新连接绑定到clientSelector上，这样就不用 IO 模型中 1w 个 while 循环在死等 Selector serverSelector = Selector.open(); // 2. clientSelector负责轮询连接是否有数据可读 Selector clientSelector = Selector.open(); new Thread(() -\u0026gt; { try { // 对应IO编程中服务端启动 ServerSocketChannel listenerChannel = ServerSocketChannel.open(); listenerChannel.socket().bind(new InetSocketAddress(3333)); listenerChannel.configureBlocking(false); listenerChannel.register(serverSelector, SelectionKey.OP_ACCEPT); while (true) { // 监测是否有新的连接，这里的1指的是阻塞的时间为 1ms if (serverSelector.select(1) \u0026gt; 0) { Set\u0026lt;SelectionKey\u0026gt; set = serverSelector.selectedKeys(); Iterator\u0026lt;SelectionKey\u0026gt; keyIterator = set.iterator(); while (keyIterator.hasNext()) { SelectionKey key = keyIterator.next(); if (key.isAcceptable()) { try { // (1) 每来一个新连接，不需要创建一个线程，而是直接注册到clientSelector SocketChannel clientChannel = ((ServerSocketChannel) key.channel()).accept(); clientChannel.configureBlocking(false); clientChannel.register(clientSelector, SelectionKey.OP_READ); } finally { keyIterator.remove(); } } } } } } catch (IOException ignored) { } }).start(); new Thread(() -\u0026gt; { try { while (true) { // (2) 批量轮询是否有哪些连接有数据可读，这里的1指的是阻塞的时间为 1ms if (clientSelector.select(1) \u0026gt; 0) { Set\u0026lt;SelectionKey\u0026gt; set = clientSelector.selectedKeys(); Iterator\u0026lt;SelectionKey\u0026gt; keyIterator = set.iterator(); while (keyIterator.hasNext()) { SelectionKey key = keyIterator.next(); if (key.isReadable()) { try { SocketChannel clientChannel = (SocketChannel) key.channel(); ByteBuffer byteBuffer = ByteBuffer.allocate(1024); // (3) 面向 Buffer clientChannel.read(byteBuffer); byteBuffer.flip(); System.out.println( Charset.defaultCharset().newDecoder().decode(byteBuffer).toString()); } finally { keyIterator.remove(); key.interestOps(SelectionKey.OP_READ); } } } } } } catch (IOException ignored) { } }).start(); } }  为什么大家都不愿意用 JDK 原生 NIO 进行开发呢？从上面的代码中大家都可以看出来，是真的难用！除了编程复杂、编程模型难之外，它还有以下让人诟病的问题：\n JDK 的 NIO 底层由 epoll 实现，该实现饱受诟病的空轮询 bug 会导致 cpu 飙升 100% 项目庞大之后，自行实现的 NIO 很容易出现各类 bug，维护成本较高，上面这一坨代码我都不能保证没有 bug  Netty 的出现很大程度上改善了 JDK 原生 NIO 所存在的一些让人难以忍受的问题。\n3. AIO (Asynchronous I/O) AIO 也就是 NIO 2。在 Java 7 中引入了 NIO 的改进版 NIO 2,它是异步非阻塞的IO模型。异步 IO 是基于事件和回调机制实现的，也就是应用操作之后会直接返回，不会堵塞在那里，当后台处理完成，操作系统会通知相应的线程进行后续的操作。\nAIO 是异步IO的缩写，虽然 NIO 在网络操作中，提供了非阻塞的方法，但是 NIO 的 IO 行为还是同步的。对于 NIO 来说，我们的业务线程是在 IO 操作准备好时，得到通知，接着就由这个线程自行进行 IO 操作，IO操作本身是同步的。（除了 AIO 其他的 IO 类型都是同步的，这一点可以从底层IO线程模型解释，推荐一篇文章：《漫话：如何给女朋友解释什么是Linux的五种IO模型？》 ）\n参考 《Netty 权威指南》第二版 https://zhuanlan.zhihu.com/p/23488863 (美团技术团队)  ","id":10,"section":"posts","summary":"IO,NIO,AIO 学习与总结 Java 中的 BIO、NIO和 AIO 理解为是 Java 语言对操作系统的各种 IO 模型的封装。程序员在使用这些 API 的时候，不需要关心操作系统层面的知识，也不","tags":["Java"],"title":"NIO_AIO_BIO学习与总结","uri":"https://cens7.github.io/2019/05/nio_aio_bio%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%80%BB%E7%BB%93/","year":"2019"},{"content":"问题 pringCloud整合的rabbitmq， 在消费端设置了group，通常情况消费端只消费了一次，偶尔碰到一次 mq被消费两次。  解决 添加groupId 分组  ","id":11,"section":"posts","summary":"问题 pringCloud整合的rabbitmq， 在消费端设置了group，通常情况消费端只消费了一次，偶尔碰到一次 mq被消费两次。 解决 添加g","tags":["Java","SpringCloud","问题"],"title":"SpringCloud中rabbitmq被消费多次","uri":"https://cens7.github.io/2018/06/springcloud%E4%B8%ADrabbitmq%E8%A2%AB%E6%B6%88%E8%B4%B9%E5%A4%9A%E6%AC%A1/","year":"2018"},{"content":"lambda基本使用 1.将List转成Map\u0026lt;Id,Person\u0026gt;  Map\u0026lt;Id,Person\u0026gt; map = list.parallelStream(). collect(Collectors.toMap(Person::getId, p -\u0026gt; p));\n 2.将List按照sex分组  Map\u0026lt;String,Person\u0026gt; map = list.parallelStream(). collect(Collectors.groupingBy(Person::getSex));\n 3.取出List的平均score  dobble avg = list.parallelStream(). mapToDouble(p -\u0026gt; p.getScore()).average().getAsDouble();\n 4.取出List中id为10的学生  Optionalop = list.parallelStream().filter(p -\u0026gt; p.getId().equals(10)).findFirst(); Person p = op.get();\n 5.取出List中所有的id  Listids = list.parallelSream().map(Person::getId).collect(Collectors.toList());\n 6.根据score,取前100名 （降序）  Listpersons =list.parallelStream(). sorted(Comparator.comparing(Person::getScore()).reversed()). limit(100).collect(Collectors.toList());//使用guava ListpeopleList1 = Ordering.natural().onResultOf(People::getId).sortedCopy(peopleList);\n 7.取出分数最高的学生信息  Person person = list.parallelStream().max(Comparator.comparing(Person::getScore()).get();\n// 只能取出最小的ID 不能取出整个对象\nInteger min = Ordering.natural().reverse().min(Iterables.transform(peopleList, People::getId));\n 8.算所有学生的分数  Long sum = list.parallelStream().map(Person::getScore).reduce((x1,x2) -\u0026gt; x1+x2).get();\n 9.求所有金钱总和  BigDecimal money = list.parallelStream().map(Person::getMoney).reduce(BigDecimal::add).get();\n 10.取出两个不同List对象中相等的Id   11.剔除List中金钱一样的对象   Collectionvalues = list.parallelStream(). collect(Collectors.toMap(Person::getMoney, p -\u0026gt; p , (p,q) -\u0026gt; p)).values();       12.将List转成Map\u0026lt;Long,List\u0026gt;。 (如果需要，可以转成Map\u0026lt;String,List\u0026gt;等等)\n Map\u0026lt;Long, List\u0026gt; result = listHello.stream().collect(Collectors.groupingBy(Person::getId));\n 13.CompletableFuture结合lambda异步执行并汇总   14.对象转map  Map\u0026lt;String, String\u0026gt; collect = privilegeObjList.stream().collect(Collectors.toMap(PlatformPrivilegeF::getModuleNo, PlatformPrivilegeF::getPrivilege));\n 15.把对象的moduleNo当Map的key，privilege当map的value List集合元素。  Map\u0026lt;String, List\u0026gt; map = privilegeObjList.stream().collect( Collectors.groupingBy(PlatformPrivilegeF::getModuleNo, Collectors.mapping(PlatformPrivilegeF::getPrivilege, Collectors.toList())));\n ","id":12,"section":"posts","summary":"lambda基本使用 1.将List转成Map\u0026lt;Id,Person\u0026gt; Map\u0026lt;Id,Person\u0026gt; map = list.parallelStream(). collect(Collectors.toMap(Person::getId, p -\u0026gt; p)); 2.将List按照sex分组 Map\u0026lt;String,Person\u0026gt; map = list.parallelStream(). collect(Collectors.groupingBy(Person::getSex)); 3.取出","tags":["Java","lambda"],"title":"Lambda基本使用","uri":"https://cens7.github.io/2017/04/lambda%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/","year":"2017"},{"content":"基本设置 关闭默认打开工程：关闭大小写敏感：换行显示10个文件选项卡：常用插件  lombok 注解 mybatis plugin maven helper String Manipulation 字符串处理 Translation 翻译  ","id":13,"section":"posts","summary":"基本设置 关闭默认打开工程：关闭大小写敏感：换行显示10个文件选项卡：常用插件 lombok 注解 mybatis plugin maven helper String Manipulation 字符串处理 Translation 翻译","tags":["idea"],"title":"idea基本设置","uri":"https://cens7.github.io/2016/12/idea%E5%9F%BA%E6%9C%AC%E8%AE%BE%E7%BD%AE/","year":"2016"},{"content":"位逻辑运算符 与运算（\u0026amp;） 与运算：两个运算数比较位都是 1，则结果为 1，否则为 0。例如：5 \u0026amp; 3 = 1\n0000 0000 0000 0000 0000 0000 0000 0101 5 转换为二进制 0000 0000 0000 0000 0000 0000 0000 0011 3 转换为二进制 0000 0000 0000 0000 0000 0000 0000 0001 换算成 10 进制为 1  或运算（|） 或运算：两个运算数比较位有一个为 1，则结果为 1，否则为 0。例如：5 | 3 = 7\n0000 0000 0000 0000 0000 0000 0000 0101 5 转换为二进制 0000 0000 0000 0000 0000 0000 0000 0011 3 转换为二进制 0000 0000 0000 0000 0000 0000 0000 0111 换算成 10 进制为 7  异或运算（^） 异或运算：两个运算数比较位不同时，其结果是 1，否则为 0。例如：5 ^ 3 = 6\n0000 0000 0000 0000 0000 0000 0000 0101 5 转换为二进制 0000 0000 0000 0000 0000 0000 0000 0011 3 转换为二进制 0000 0000 0000 0000 0000 0000 0000 0110 换算成 10 进制为 6  非运算（~） 非运算：也叫做补，一元运算符，对其运算数的每一位取反。例如：~5 = -6\n0000 0000 0000 0000 0000 0000 0000 0101 5 转换为二进制 1111 1111 1111 1111 1111 1111 1111 1010 取非后的原码 1000 0000 0000 0000 0000 0000 0000 0110 转换补码，换算成 10 进制为 -6  ####其它\n  Java 中整数类型（byte、short、int 和 long）在内存中是以有符号的二进制补码表示。所以位运算时，首先要转换为原码。\n  补码转原码：补码转原码和原码转补码的方法是一样的，取反 + 1（补码的补码是原码）。\n  当位运算数是 byte 和 short 类型时，将自动把这些类型扩大为 int 型（32 位）。\n  计算出 n 位二进制数所能表示的最大十进制数位移算法：-1L ^ (-1L \u0026laquo; n) 或 ~(-1L \u0026laquo; n)。\n  byte 和 int 相互转换\n  int i = 234; byte b = (byte) i; // 结果：b = -22 // 转换过程： // 0000 0000 0000 0000 0000 0000 1110 1010 # int 234 的补码（与原码相等） // 1110 1010 # byte 低位截取 // 1001 0110 # 求得补码，转为 10 进制为 -22 int x = b ; // 结果为：x = -22；8 位 byte 的转 32 的 int，值不变。 int y = b \u0026amp; 0xff; // 结果为：x = 234； 可以通过将其和 0xff 进行位与（\u0026amp;）得到它的无符值 // 转换过程： // 1001 0110 # byte -22 的原码 // 1000 0000 0000 0000 0000 0000 0001 0110 # int -22 的原码 // 1111 1111 1111 1111 1111 1111 1110 1010 # int -22 补码 // 0000 0000 0000 0000 0000 0000 1111 1111 # 0xff 的二进制数 // 0000 0000 0000 0000 0000 0000 1110 1010 # 和 0xff 进与操作的结果，转换为 10 进制为 234  ","id":14,"section":"posts","summary":"位逻辑运算符 与运算（\u0026amp;） 与运算：两个运算数比较位都是 1，则结果为 1，否则为 0。例如：5 \u0026amp; 3 = 1 0000 0000 0000 0000 0000 0000 0000 0101 5 转换为二进制 0000 0000 0000 0000","tags":["数据结构"],"title":"Java位运算2_位运算","uri":"https://cens7.github.io/2016/02/java%E4%BD%8D%E8%BF%90%E7%AE%972_%E4%BD%8D%E8%BF%90%E7%AE%97/","year":"2016"},{"content":"左移运算（\u0026laquo;） value \u0026lt;\u0026lt; num   num 指定要移位值；value 移动的位数。\n 将左操作数（value）转为二进制数后向左边移动 num 位，并且在低位补 0，高位丢弃。\n例如：5 \u0026laquo; 2\n0000 0000 0000 0000 0000 0000 0000 0101 5 的补码（同原码） 0000 0000 0000 0000 0000 0000 0001 0100 左移 2 位后，低位补 0。换算成 10 进制为 20  如果移动的位数超过了该类型的最大位数，那么编译器会对移动的位数取模。如：对 int 类型（最大位数 32）的数值移动 33 位，实际上只移动了 33 % 32 = 1 位。\n 注：n 位二进制，最高位为符号位，因此表示的数值范围：−2(𝑛−1) —— 2(𝑛−1)−1，所以模为：2(𝑛−1)。\n 在数字没有溢出的前提下，对于正数和负数，左移一位都相当于乘以 2 的 1 次方，左移 n 位就相当于乘以 2 的 n 次方。如：5 \u0026laquo; 2 相当于 5∗22=20。\n如果移进高阶位（int 31 或 long 63 位），那么该值将变为负值。如：1 \u0026laquo; 31 = -2147483648\n右移运算（\u0026raquo;） value \u0026gt;\u0026gt; num   num 指定要移位值；value 移动的位数。\n 将左操作数（value）转为二进制数后向右边移动 num 位，符号位不变，高位补上符号位（若左操作数是正数，则高位补 0，若左操作数是负数，则高位补 1），低位丢弃。\n右移时，被移走的最高位（最左边的位）由原来最高位的数字补充，这叫做符号位扩展（保留符号位）（sign extension），在进行右移操作时用来保持负数的符号。\n例如：7 \u0026raquo; 2\n0000 0000 0000 0000 0000 0000 0000 0111 7 的补码（同原码） 0000 0000 0000 0000 0000 0000 0000 0001 右移 2 位后，高位补 0。换算成 10 进制为 1  例如：-7 \u0026raquo; 2\n1000 0000 0000 0000 0000 0000 0000 0111 -7 的原码 1111 1111 1111 1111 1111 1111 1111 1000 -7 的反码 1111 1111 1111 1111 1111 1111 1111 1001 -7 的补码 1111 1111 1111 1111 1111 1111 1111 1110 右移 2 位后，高位补 1 1000 0000 0000 0000 0000 0000 0000 0010 补码转原码。换算成 10 进制为 -2  正数右移 n 位相当于除以 2 的 n 次方并且舍弃了余数。如：7 \u0026raquo; 2 相当于： 7/22=1。\n负数右移 n 位相当于除以 2 的 n 次方，如果有余数 -1。如：-7 \u0026raquo; 2 相当于： 7∗22−1=−2。\n例子：\npublic static void main(String[] args) { // 左移 int i = 16; // 在二进制i的右边加两个零，也就是二进制乘以100 // 100换算成10进制，乘以4 // 也可能看作是乘以2的2次幂 int i1 = i \u0026lt;\u0026lt; 2; int i2 = i * (2 * 2); System.out.println(\u0026quot;i1 = \u0026quot; + i1 + \u0026quot;, i2 = \u0026quot; + i2); // 在二进制i的右边加三个零，也就是二进制乘以1000 // 1000换算成10进制，乘以8 // 也可能看作是乘以2的3次幂 int i3 = i \u0026lt;\u0026lt; 3; int i4 = i * (2 * 2 * 2); System.out.println(\u0026quot;i3 = \u0026quot; + i3 + \u0026quot;, i4 = \u0026quot; + i4); // -------------------------------------------------------- // 右移 int j = 16; // 在二进制i的右边减少两个零，也就是二进制除以100 // 100换算成10进制，除以4 // 也可能看作是除以2的2次幂 int j1 = j \u0026gt;\u0026gt; 2; int j2 = i / (2 * 2); System.out.println(\u0026quot;j1 = \u0026quot; + j1 + \u0026quot;, j2 = \u0026quot; + j2); }  无符号右移（\u0026raquo;\u0026gt;） value \u0026gt;\u0026gt;\u0026gt; num   num 指定要移位值；value 移动的位数。\n 将左操作数（value）转为二进制数后向右边移动 num 位，0 补最高位（忽略了符号位扩展）。\n无符号右移运算只是对 32 位和 64 位的值有意义。\n例如：-7 \u0026raquo;\u0026gt; 2\n1000 0000 0000 0000 0000 0000 0000 0111 -7 的原码 1111 1111 1111 1111 1111 1111 1111 1001 -7 的补码 0011 1111 1111 1111 1111 1111 1111 1110 右移 2 位后，高位补 0。换算成 10 进制为 1073741822  ","id":15,"section":"posts","summary":"左移运算（\u0026laquo;） value \u0026lt;\u0026lt; num num 指定要移位值；value 移动的位数。 将左操作数（value）转为二进制数后向左边移动 num 位，并且在低位补 0，","tags":["数据结构"],"title":"Java位运算1_左移、右移","uri":"https://cens7.github.io/2016/02/java%E4%BD%8D%E8%BF%90%E7%AE%971_%E5%B7%A6%E7%A7%BB%E5%8F%B3%E7%A7%BB/","year":"2016"},{"content":"广义表：  L=(a,b) L长度为2，深度为1\nL=(x,(a,b)）长度为2，深度为2\nL=(x,(a,b,c),y) 长度为3，深度为6\nL=(a,a,a,(a,\u0026hellip;))长度为4，深度为无穷大\n 无向图G5的邻接矩阵是： A1 ={0，1，1，1}\n{1，0，1，1}\n{1，1，0，0}\n{1，1，0，0}\n 有向图G6的邻接矩阵是：\n A2 = {0，1，0，0，0}\n{1，0，0，0，1}\n{0，1，0，1，0}\n{1，0，0，0，0}\n{0，0，0，1，0}\n  排序：内部排序：排序时不涉及数据的内、外存交换。适用于记录个数不很多的小文件。包括：插入排序、选择排序、交换排序、归并排序和分配排序。 外部排序：过程中要进行数据的内、外存交换。适用于记录个数太多，不能一次放到内存的大文件。     算法名 类别 平均 最好 最坏 辅助 稳定性     直接插入排序 插入排序 O(n²) O(n) O(n²) O(1) 稳定   希尔排序 插入排序 O(n^1.5) O(n) O(n²) O(1) 不稳定   简单选择排序 选择排序 O(n²) O(n²) O(n²) O(1) 不稳定   堆排序 选择排序 O(n㏒2n) O(n㏒2n) O(n㏒2n) O(1) 不稳定   冒泡排序 交换排序 O(n²) O(n) O(n²) O(1) 稳定   快速排序 交换排序 O(n㏒2n) O(n㏒2n) O(n²) O(n㏒2n) 不稳定   归并排序 归并排序 O(n㏒2n) O(n㏒2n) O(n㏒2n) O(1) 稳定   基数排序 基数排序 O(d(r+n)) O(d(rd+n)) O(d(r+n)) O(rd+n) 稳定     二叉树节点的度指父节点对应的下面孩子节点个数，最大为2。 BFS（Breadth-first Search）宽度优先搜索。先从根节点开始，搜索根节点左侧V1；搜索根节点右侧V2；搜索V1左侧V11；搜索V2右侧，当V2节点已经被V1搜索过，则V2停止。 DFS（Depth-first Search）深度优先搜索。先从根节点开始，搜索根节点左侧V1下面所有节点；搜索完再搜索根节点右侧V2所有节点。当V2节点已经被V1搜索过，则V2停止。 二路归并排序是把数组分成 n/2 +1个子数组，子数组内排序完成，在一直两两归并排序下去成一个数组。 图的广度优先遍历(BFS)类似于树的层次遍历。 图的深度优先遍历(DFS)类似于树的前序遍历。 直接插入排序后，可能未能选出一个元素放到其最终位置上。 快速排序、冒泡排序、希尔排序、堆排序原理。 二叉树等改路情况下平均查找长度等于= （∑(节点数量×节点个数)）÷所有节点个数。 堆排序是一种树形选择排序。 设线性表的长度为n，则顺序查找成功时的平均查找长度为 (n+1)/2。 抽象数据类型是指抽象数据的组织和与之相关的操作。 当三交矩阵的常数为0时，n阶三角矩阵的非零元素个数为n(n+1)/2。 有向图中的极大连通子图称作有向图的强连接分量。  ","id":16,"section":"posts","summary":"广义表： L=(a,b) L长度为2，深度为1 L=(x,(a,b)）长度为2，深度为2 L=(x,(a,b,c),y) 长度为3，深度为6 L=(a,a,a,(a,\u0026hellip;))长度为","tags":["数据结构"],"title":"数据结构学习笔记_1","uri":"https://cens7.github.io/2015/11/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_1/","year":"2015"}],"tags":[{"title":"docker","uri":"https://cens7.github.io/tags/docker/"},{"title":"Dubbo","uri":"https://cens7.github.io/tags/dubbo/"},{"title":"idea","uri":"https://cens7.github.io/tags/idea/"},{"title":"Java","uri":"https://cens7.github.io/tags/java/"},{"title":"Kotlin","uri":"https://cens7.github.io/tags/kotlin/"},{"title":"lambda","uri":"https://cens7.github.io/tags/lambda/"},{"title":"redis","uri":"https://cens7.github.io/tags/redis/"},{"title":"SpringCloud","uri":"https://cens7.github.io/tags/springcloud/"},{"title":"webSocket","uri":"https://cens7.github.io/tags/websocket/"},{"title":"xss","uri":"https://cens7.github.io/tags/xss/"},{"title":"分库分表","uri":"https://cens7.github.io/tags/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/"},{"title":"协程","uri":"https://cens7.github.io/tags/%E5%8D%8F%E7%A8%8B/"},{"title":"多线程","uri":"https://cens7.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"title":"安全","uri":"https://cens7.github.io/tags/%E5%AE%89%E5%85%A8/"},{"title":"工具","uri":"https://cens7.github.io/tags/%E5%B7%A5%E5%85%B7/"},{"title":"数据库","uri":"https://cens7.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"title":"数据结构","uri":"https://cens7.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"title":"架构","uri":"https://cens7.github.io/tags/%E6%9E%B6%E6%9E%84/"},{"title":"测试","uri":"https://cens7.github.io/tags/%E6%B5%8B%E8%AF%95/"},{"title":"问题","uri":"https://cens7.github.io/tags/%E9%97%AE%E9%A2%98/"}]}